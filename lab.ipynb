{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce8a552",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/iu5git/Deep-learning/blob/main/notebooks/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# العمل المخبري رقم 1\n",
    "\n",
    "## المهمة\n",
    "\n",
    "يجب التعرف على إطار عمل التعلم الآلي PyTorch وتنفيذ ثلاث مهام:\n",
    "1. الانحدار وفقًا لنظرية التقريب الشامل، التفاضل اليدوي\n",
    "2. التصنيف الثنائي باستخدام التفاضل التلقائي في PyTorch\n",
    "3. تدريب شبكة عصبية كاملة الاتصال لتصنيف 3 فئات من الصور من مجموعة بيانات CIFAR100 وفقًا للمثال المحدد ثم تحسين الدقة على مجموعة الاختبار.\n",
    "\n",
    "للمهمة 3 يجب تشكيل مجموعة فرعية خاصة بك وفقًا للخيار المحدد من CIFAR100 وفقًا للخيار المحدد. \n",
    "\n",
    "يتم تنفيذ المختبرات على منصة Google Colab ما عليك سوى الانتقال إلى الرابط في بداية ال Notebook . كما يمكن العمل مع Notebook المختبر محليًا .\n",
    "\n",
    "### يجب أن يحتوي التقرير على:\n",
    "- صفحة العنوان\n",
    "- المهمة مع الخيار المحدد\n",
    "- لقطات شاشة وتفسيرات قصيرة لكل مرحلة من مراحل العمل المخبري\n",
    "- جدول نهائي بالنتائج لجميع خيارات التدريب\n",
    "\n",
    "# الخيارات للمهمة 3\n",
    "\n",
    "يجب عليك استخدام الفئات التالية من CIFAR100:\n",
    "<div dir=\"rtl\">\n",
    "    \n",
    "1. رقم المجموعة + 15\n",
    "2. رقم الخيار + 56\n",
    "  3. ИУ5 (رقم الخيار + 21)؛ ГУИМЦ (80) ؛  (الأجانب(90)  \n",
    "<div>\n",
    "\n",
    "# مهام للعمل الذاتي\n",
    "\n",
    "1. قم بتحليل نتائج تدريب النموذج الخاص بك. ماذا تخبرنا دقة النموذج على مجموعة التدريب واختبار البيانات؟ مع أي الفئات يتعامل النموذج بشكل أفضل ولماذا؟\n",
    "2. قم بتحليل نتائج التدريب. هل تحدث زيادة في تعلم النموذج الخاص بك؟ ماذا يجب أن تفعل لتقليل ذلك (دون استخدام الانتظام)؟\n",
    "3. قم بتغيير حجم الدفعة، ولكن حافظ على العدد الإجمالي للتكرارات. قم بتحليل نتائج التدريب مع المعلمات الجديدة. ماذا تغير ولماذا؟\n",
    "4. قلل من معدل التعلم وزد من العدد الإجمالي للتكرارات لزيادة دقة النموذج.\n",
    "5. قم بتغيير النموذج الخاص بك - غيّر عدد الخلايا العصبية والطبقات. قم بتحليل نتائج تدريب النموذج الجديد. ابحث عن أفضل المعلمات لهذا النموذج.\n",
    "6. حدد الإجراءات التي ساعدت في زيادة دقة النموذج الخاص بك وفسر السبب.\n",
    "\n",
    "\n",
    "# تعليقات على العمل الذاتي\n",
    "<div dir=\"rtl\">\n",
    "- يتم تغيير معدل التعلم وحجم الدفعة فقط بعد تحديد لحظة الزيادة في التعلم - الحقبة التي تكون فيها الخطأ على مجموعة الاختبار هو الأدنى. خلاف ذلك، قد يؤدي تحسين الخطوات إلى تعزيز زيادة التعلم (تحسن أثناء التدريب، وتدهور في الاختبار).\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "- يجب أن يؤدي زيادة حجم الدفعة مع نفس عدد التكرارات إلى تحسين التعلم قليلاً (في المتوسط). لأننا نقوم بنفس العدد، ولكن بخطوات أفضل. قد لا يتوافق ذلك مع التجربة لأسباب مختلفة، ولكن من النظرية نتوقع حدوث تحسين ما.\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "- عدد المرات التي تقوم فيها بتغيير معدل التعلم أو حجم الدفعة يجب أن يساوي عدد مرات تغيير عدد العصور للحفاظ على التكرارات. في الممارسة العملية، هذه الشروط ليست ضرورية، لأننا عند إعادة التدريب نغير العديد من المعلمات في نفس الوقت. لكننا نتعلم، لذلك ندرس سلوك كل معلمة على حدة: لا يمكننا مقارنة 5 خطوات كبيرة و7 خطوات صغيرة، لكن يمكننا مقارنة 5 خطوات كبيرة و5 خطوات صغيرة.\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "- عند تغيير النموذج، يجب البحث عن المعلمات الجديدة مرة أخرى - هذا نموذج جديد. ليس من الضروري إعادة شرح جميع الخطوات، فقط قم بذلك بنفسك - ابحث عن زيادة التعلم وابحث عن معدل وحجم دفعة سيكونان أفضل.\n",
    "</div>\n",
    "\n",
    "# أسئلة المراقبة للدفاع\n",
    "\n",
    "1. شبكة عصبية كاملة الاتصال، اشرح الهيكل والحسابات والغرض من الطبقات ومكونات الخلايا العصبية.\n",
    "2. اذكر عدد الخلايا العصبية والاتصالات والأوزان في شبكة عصبية كاملة الاتصال.\n",
    "3. وصف مهام الانحدار والتصنيف. ما هي دوال الخسارة المستخدمة في هذه المهام؟\n",
    "4. وصف هيكل مجموعة البيانات، والغرض من أجزائها.\n",
    "5. وصف خوارزمية الانحدار العشوائي. اذكر غرض المعلمات. ما الفرق بين الانحدار العشوائي والانحدار على دفعات؟\n",
    "6. ما هي الحقبة، والتكرار، وحجم الدفعة في التدريب. كيف ترتبط ببعضها؟\n",
    "7. ما هو التعلم تحت الإشراف، والتعلم بدون إشراف، والتعلم المعزز؟ قدم أمثلة على الأساليب والمهام لكل نوع من أنواع التعلم.\n",
    "---\n",
    "# وصف الجدول النهائي\n",
    "\n",
    "|  تكوين الشبكة العصبية   |  المعلمات الفائقة  |  الدقة  |  التعليق  |\n",
    "|----------|----------|----------|----------|\n",
    "|  FC(10), FC(3)   | lr = 0.003, batch_size = 128, epochs = 100  |  اختبار = 70%، تدريب = 98%  |  الخيار الأساسي  |\n",
    "|  FC(10), FC(3)   | lr = 0.001, batch_size = 128, epochs = 300  |  اختبار = 72%، تدريب = 99%  |  تم تقليل معدل التعلم بمقدار 3 مرات، لتعويض ذلك زاد عدد العصور بنفس المقدار  |\n",
    "\n",
    "\n",
    "### طرق ودوال PyTorch\n",
    "<div dir = \"rtl\">\n",
    "(Documentation: https://pytorch.org/docs/stable/index.html)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## المكتبات:\n",
    "\n",
    "<div dir=\"rtl\">* __np__ - مكتبة NumPy للعمل مع المصفوات متعددة الأبعاد للبيانات</div>  \n",
    "<div dir=\"rtl\">* __pickle__ - مكتبة Pickle لتسلسل وتفكيك هياكل البيانات في لغة Python</div>  \n",
    "<div dir=\"rtl\">* __sklearn__ - مكتبة تنفذ في الأساس طرق التعلم الآلي الكلاسيكي وأدوات للعمل معها</div>  \n",
    "<div dir=\"rtl\">* __PIL__ - مكتبة خفيفة الوزن Pillow للعمل مع الصور وعرض العناصر الرسومية مباشرة في Jupyter Notebook</div>  \n",
    "<div dir=\"rtl\">* __matplotlib__ - مكتبة لرسم الرسوم البيانية، تتكرر في الغالب واجهة برمجة التطبيقات الخاصة بـ Matlab</div>  \n",
    "<div dir=\"rtl\">* __torch__ - مكتبة PyTorch للتعلم العميق للشبكات العصبية</div>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "    \n",
    "<div dir=\"rtl\"><h2>الاختصارات المعتمدة:</h2></div>  \n",
    "<div dir=\"rtl\">* torch.nn - nn</div>  \n",
    "<div dir=\"rtl\">* torch.nn.functional - F</div>  \n",
    "<div dir=\"rtl\">* torch.optim - optim</div>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\"><h1>الطرق</h1></div>  \n",
    "<div dir=\"rtl\">* __torch.Tensor__ - ينشئ تينسور من مصفوفة Numpy متعددة الأبعاد ويرث نوع بياناته. بشكل افتراضي، يتم تخصيص الذاكرة للتينسورات على وحدة المعالجة المركزية (CPU). عند تعيين علامة __requires_grad__، تتعقب تلقائيًا التدرجات باستخدام محرك autograd، الذي يبني رسمًا بيانيًا ديناميكيًا للحساب. يمكن أيضًا تمكين تتبع التينسور __t__ باستخدام طريقة __t.requires_grad_(True)__ . في هذه الحالة، بعد استدعاء طريقة __backward__، سيتم تسجيل المشتقات في حقل __grad__. يمكن مسح مشتقات التينسور __t__ باستدعاء طريقة __t.grad.zero_()__. لاستخدام طريقة __detach__ لقطع الحسابات غير الضرورية للمشتقات، والتي تنشئ نسخة من التينسور، مع إزالة علامة __requires_grad__، ويتوقف تتبع محرك autograd.</div>\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">* __torch.numpy__ - ينشئ مصفوفة بيانات NumPy متعددة الأبعاد من التنسور.</div>  \n",
    "<div dir=\"rtl\">* __torch.item__ - يعيد عددًا، ولكن فقط إذا كانت رتبة التنسور 0. خلاف ذلك، يعطي خطأ ويجب استخدام torch.numpy.</div>  \n",
    "<div dir=\"rtl\">* __torch.uint8__, __torch.int16__, __torch.int64__, __torch.float32__ - تحويل المصفوفة إلى نوع جديد، مشابه لـ NumPy. يتم استخدام الطريقة .to (على سبيل المثال <code>t.to(torch.int64))</code> للتحويل. بشكل افتراضي، يتم إجراء جميع الحسابات على الرسم البياني في float64، وهناك أيضًا إمكانية استخدام الدقة المختلطة (شيء في float16، وشيء في float64)، ولكن تعتبر هذه تقنية متقدمة.</div>  \n",
    "<div dir=\"rtl\">* __torch.ones__, __torch.zeros__, __torch.transpose__, __torch.reshape__ - واجهة برمجة التطبيقات مشابهة لـ NumPy.</div>  \n",
    "<div dir=\"rtl\">* __torch.rand__ - إنشاء تنسور عشوائي بأرقام في النطاق من 0 إلى 1. يتم سرد الأبعاد عبر الفواصل.</div>  \n",
    "<div dir=\"rtl\">* __torch.t__ - نقل التنسور، مشابه لـ __numpy.transpose__. إذا كان هناك تنسور X، يمكن نقله باستخدام <code>X.t()</code>.</div>  \n",
    "<div dir=\"rtl\">* __torch.sum__ - جمع عناصر التنسور على طول المحور المحدد __axis__. إذا تم الجمع على طول المحور الأخير، يمكن تحديد الرقم -1 بدلاً من ذلك. للحفاظ على أبعاد التنسور الأصلية، يجب تعيين علامة __keepdims__.</div>  \n",
    "<div dir=\"rtl\">* __torch.maximum__ - يقوم بالمقارنة العنصرية بين التنسورات ويعيد الحد الأقصى من العناصر. في الممارسة العملية، يتم استخدامه لتنفيذ بعض وظائف التنشيط للشبكة العصبية.</div>  \n",
    "<div dir=\"rtl\">* __torch.mm__ - ضرب التنسورات. بالنسبة لمصفوفتين ثنائيتين الأبعاد بأبعاد (M, N) و (N, K)، سيكون ناتج هذه الطريقة مصفوفة ثنائية الأبعاد بأبعاد (M, K).</div>  \n",
    "<div dir=\"rtl\">* __torch.exp__ - يعيد نفس وظيفة __numpy.exp__ - رفع التنسور إلى قوة الأساس بصورة عنصرية.</div>  \n",
    "<div dir=\"rtl\">* __torch.log__ - عملية تسجيل عنصري للتنسور - أخذ اللوغاريتم الطبيعي، وهو العملية العكسية للرفع للقوة.</div>  \n",
    "<div dir=\"rtl\">* __torch.flatten__ - مشابه لـ NumPy .reshape(-1)، إذا تم تحديد معلمة start_dim، فسيبدأ \"تسوية\" المصفوفة بدءًا من الرقم المحدد. أي لتحويل التنسور t مع الشكل (100, 32, 32, 3) إلى الشكل (100, 3072) يكفي كتابة <code>torch.flatten(t, start_dim=1).</code></div>  \n",
    "<div dir=\"rtl\">* __F.one_hot__ - واحدة من الطرق العديدة للحصول على ترميز حار للفئة في شكل تنسور PyTorch. على سبيل المثال، بالنسبة لخمس فئات، سيكون الترميز الحار للفئة \"4\" هو [0, 0, 0, 1, 0].</div>  \n",
    "<div dir=\"rtl\">* __torch.utils.data.TensorDataset__ - إنشاء تنسورات مرتبطة، مثل أمثلة التدريب والعلامات المقابلة. يتم تمرير التنسورات كمعلمات. طريقة مقبولة لإنشاء مجموعة بيانات عندما تكون عينة التدريب صغيرة تمامًا وتناسب بالكامل في الذاكرة.</div>  \n",
    "<div dir=\"rtl\">* __torch.utils.data.DataLoader__ - تعتمد أداة تحميل البيانات في PyTorch على فئة DataLoader. إنها كائن Python يتكرر عبر مجموعة البيانات، مع دعم مجموعة البيانات بأسلوب الخريطة والمكرر؛ إعدادات ترتيب تحميل البيانات؛ تقسيم تلقائي إلى دفعات صغيرة؛ تحميل البيانات في عمليات/خيوط متعددة. أكثر المعلمات فائدة في الباني هي حجم الدفعة الصغيرة __batch_size__ وعدد العمليات المتوازية __num_workers__. لمزج البيانات (لتحقيق تقارب أفضل)، يجب تعيين علامة __shuffle__ إلى True.</div>  \n",
    "<div dir=\"rtl\">* __torch.save__ - حفظ معلمات النموذج على وسائط التخزين الدائمة. لذلك يتم تمرير model.state_dict() كأول معلمة، حيث model هو النموذج العصبي المدرب، والثاني هو المسار مع اسم الملف.</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div dir=\"rtl\"><h1>إنشاء النماذج</h1>:</div>\n",
    "\n",
    "<div dir=\"rtl\">يتم إنشاء النماذج باستخدام وحدة nn، حيث تم تنفيذ أشهر كتل الشبكات العصبية أو الطبقات في الوحدة، مثل:</div>\n",
    "<div dir=\"rtl\">* طبقة الاتصال الكامل Linear</div>  \n",
    "<div dir=\"rtl\">* الطبقة التلافيفية Conv2d</div>  \n",
    "<div dir=\"rtl\">* تجميع MaxPool2d</div>  \n",
    "<div dir=\"rtl\">* التطبيع BatchNorm2d</div>  \n",
    "<div dir=\"rtl\">* مجموعة من وظائف التنشيط ReLU و Softmax و Tanh</div>  \n",
    "<div dir=\"rtl\">* طبقات تنظيم، مثل Dropout</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h4>في هذه التجربة العملية، سوف ندرس فقط كتلتين من كتل الشبكة العصبية من القائمة أعلاه، وهما Linear و ReLU.</h4>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\" style=\"margin-top: 20px;\">\n",
    "    يمكن تعيين النموذج بطريقتين:\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\" style=\"margin-top: 20px;\">\n",
    "\n",
    "<div dir=\"rtl\">1. باستخدام nn.Sequential</div>\n",
    "<div dir=\"rtl\">2. من خلال وراثة الفئة nn.Module</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <div dir=\"rtl\">الطريقة الأولى مناسبة لإنشاء نماذج بسيطة بدون تفرعات. يمكن تصورها أساسًا كخط تجميع، حيث يتم تمرير التنسور المدخل عبر سلسلة من التحويلات المتعاقبة للحصول على التنسور الناتج.</div>\n",
    "    <div dir=\"rtl\">إذا كان من الضروري تطبيق هياكل أكثر تعقيدًا، حيث يمكن أن تنقسم مسارات خط التجميع إلى عدة أجزاء، يتم استخدام nn.Module. يسمح هذا النهج بتنفيذ مجموعة متنوعة من الهياكل.</div>\n",
    "    <div dir=\"rtl\">لإنشاء بيرسيبترون متعدد الطبقات بسيط مع طبقة مخفية واحدة ودالة غير خطية، يكفي كتابة الكود التالي وفقًا للطريقة الأولى:</div>\n",
    "</div>\n",
    "\n",
    "    model = nn.Sequential(\n",
    "      nn.Linear(input_dims, hidden_dims),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dims, num_classes) \n",
    "    )\n",
    "\n",
    "<div dir=\"rtl\">لإنشاء بيرسيبترون متعدد الطبقات بسيط مع طبقة مخفية واحدة ودالة غير خطية، وفقًا للطريقة الثانية، يجب إنشاء فئة (class) ونموذج (model) ككائن من هذه الفئة.</div>\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dims, hidden_dims, num_classes,\n",
    "                     *args, **kwargs):\n",
    "            super(MLP, self).__init__()\n",
    "            self.fc1 = Linear(input_dims, hidden_dims)\n",
    "            self.fc2 = Linear(hidden_dims, num_classes)\n",
    "        \n",
    "        def forward(self, input):\n",
    "             x = self.fc1(input)\n",
    "             x = F.relu(x)\n",
    "             x = self.fc2(x)\n",
    "             return x\n",
    "    \n",
    "    model = MLP(input_dims, hidden_dims, num_classes) \n",
    "\n",
    "<div dir=\"rtl\">في هذه الحالة، يُسمح بتضمين nn.Module و nn.Sequential داخل وحدات (modules) أخرى، مما يسمح بإنشاء بنى نماذج معقدة جدًا.</div>\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h4>تدريب النماذج:</h4>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">قبل تدريب النماذج، من الضروري اختيار دالة خسارة (Loss function) ومُحسّن (Optimizer). تتوفر دوال خسارة مختلفة أيضًا في وحدة nn:</div>\n",
    "<div dir=\"rtl\">* __nn.MSELoss__ - متوسط الخطأ التربيعي (y_true - y_pred)**2</div>\n",
    "<div dir=\"rtl\">* __nn.BCEWithLogitsLoss__ - الانتروبيا المتقاطعة الثنائية لمهام التصنيف الثنائي</div>\n",
    "<div dir=\"rtl\">* __nn.CrossEntropyLoss__ - الانتروبيا المتقاطعة الفئوية لمهام التصنيف متعدد الفئات</div>\n",
    "\n",
    "<div dir=\"rtl\">كبديل، يمكن تنفيذ دالة خسارة (Loss function) يدويًا، على سبيل المثال لـ MSELoss:</div>\n",
    "\n",
    "    inputs, y = batch\n",
    "    ...\n",
    "    output = model(inputs)\n",
    "    loss = ((output - y)**2).sum()\n",
    "    ...\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h4>المُحسِّنات:</h4>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">تحتوي وحدة __torch.optim__ على المُحسِّنات. هناك العديد من المُحسِّنات للدالة الهدف، ومن الكلاسيكيين هو طريقة النزول العشوائي للتدرج (Stochastic Gradient Descent) أو SGD. في مُنشئ الفئة، يجب تمرير أوزان النموذج، بالإضافة إلى تحديد خطوة التعلم أو learning rate.</div>\n",
    "\n",
    "<div dir=\"rtl\">لتحويل النموذج إلى حالة التدريب، يجب استدعاء الطريقة __train__. بعد ذلك، يكون النموذج جاهزًا للتدريب.</div>\n",
    "\n",
    "<div dir=\"rtl\">لتدريب نماذج الشبكات العصبية، يتم استخدام النزول التدرجي وأنواعه، والتي تستند إلى طريقة الاقترابات المتتالية.</div>\n",
    "\n",
    "<div dir=\"rtl\">خلال عصر واحد، يتم اختيار مرور المُكرر عبر مجموعة البيانات بالكامل، وفي كل تكرار - يتم تحسين معلمات النموذج باستخدام الدفعة الحالية الصغيرة (mini-batch). يقوم PyTorch تلقائيًا بحساب المشتقات عند استدعاء الطريقة __backward__، التي تم تطبيقها على دالة الخسارة.</div>\n",
    "\n",
    "<div dir=\"rtl\">مع ذلك، عند استدعاء مُجدَّد، ستضاف قيم المشتقات الجديدة إلى المشتقات السابقة المحسوبة. لذلك، لتجنب التأثيرات غير المرغوب فيها، من المعتاد تنظيف القيم السابقة للمشتقات في كل تكرار باستخدام الطريقة __zero_grad__، التي تم تطبيقها على مثيل مُحسِّن الفئة.</div>\n",
    "\n",
    "<div dir=\"rtl\">لتحديث معلمات الشبكة العصبية، تُستخدم الطريقة __step__، التي تم تطبيقها على مثيل مُحسِّن الفئة.</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h4>تحقق من جودة النماذج:</h4>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">لتحويل النموذج إلى حالة التحقق، يجب استدعاء الطريقة __eval__. بعد ذلك، يكون النموذج جاهزًا للتحقق.</div>\n",
    "\n",
    "<div dir=\"rtl\">يجب قطع التوتر الناتج عن تنبؤات النموذج عن الرسم البياني الحسابي. يتم استخدام الطريقة __detach__، التي تم تطبيقها على التوتر الناتج عن النموذج. خلاف ذلك، قد تحدث تسريبات في الذاكرة. تقوم الطريقة __numpy__ بتحويل التوتر إلى مصفوفة NumPy متعددة الأبعاد.</div>\n",
    "\n",
    "<div dir=\"rtl\">بشكل افتراضي، يقوم النموذج بإخراج ما يُعرف بـ \"لوجيتس\" (logits) للفئات، وليس احتمالاتها. للحصول على الاحتمالات، يجب تطبيق دالة التنشيط __Softmax__. ومع ذلك، في الممارسة العملية، ليس من الضروري ذلك، حيث أن قيمة اللوجيتس تتوافق مع احتمالات الفئات، وللحصول على رقم الفئة الأكثر احتمالًا، يمكن تخطي هذه الخطوة. يتم الحصول على رقم الفئة إما من خلال الطريقة __argmax__ أو من خلال الطريقة __argsort__، حيث تسمح الأخيرة بحساب مقاييس مثل Accuracy@5 ومقاييس الترتيب.</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h4>استيراد المكتبات الضرورية</h4>\n",
    "</div>\n",
    "\n",
    " In[1]:\n",
    "\n",
    "```python\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    import pickle\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.datasets import make_circles, make_moons\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "```\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h1>الجزء 1. مشكلة الانحدار وفقًا لنظرية التقريب العالمية، الاشتقاق اليدوي</h1>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\"><h2>توليد العينة وتهيئة معلمات الشبكة العصبية</h2> </div>\n",
    "\n",
    " In[2]:\n",
    "\n",
    "```python\n",
    "    X = (np.arange(100)/100 - 0.5).repeat(5)\n",
    "    \n",
    "    y = 1/(1+np.exp(-10*X))\n",
    "    yn = np.random.normal(scale=0.05, size=y.size)+y\n",
    "    \n",
    "    plt.plot(X, yn)\n",
    "    plt.plot(X, y, linestyle='--', c='k')\n",
    "    ################################################\n",
    "    tensor_X = torch.Tensor(X.reshape(-1, 1))\n",
    "    tensor_y = torch.Tensor(yn.reshape(-1, 1))\n",
    "    \n",
    "    HIDDEN_SIZE = 64\n",
    "    # Инициализация весов MLP с одним скрытым слоём\n",
    "    weights_1 = (torch.rand(1, HIDDEN_SIZE)-.5)/10\n",
    "    bias_1 = torch.zeros(HIDDEN_SIZE)\n",
    "    \n",
    "    weights_2 = (torch.rand(HIDDEN_SIZE, 1)-.5)/10\n",
    "    bias_2 = torch.zeros(1)\n",
    "```\n",
    "\n",
    "<div dir=\"rtl\" style=\"margin-top: 70px;\">\n",
    "    <img align=\"right\" src=\"Recources/pic1.png\" height=\"300px\" width=\"580px\"/>  \n",
    "    <hr style=\"margin-top: 70px; margin-bottom: 70px;\"> \n",
    "</div>\n",
    "\n",
    "<div style=\"height: 80px;\"></div>\n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br>\n",
    "\n",
    "<div dir=\"rtl\" style=\"margin-top: 40px;\">\n",
    "    <h3>تدريب الشبكة العصبية لمشكلة الانحدار</h3>\n",
    "</div>\n",
    "\n",
    "In[3]:\n",
    "```python\n",
    "   # Define the non-linearity function\n",
    "relu = lambda x: torch.maximum(x, torch.Tensor([0]))\n",
    "# Forward pass\n",
    "forward = lambda x: (weights_2.t()*relu((weights_1*x) + bias_1)\n",
    "                      ).sum(axis=-1, keepdims=True) + bias_2\n",
    "loss = lambda y, y_: ((y-y_)**2).sum(axis=-1)\n",
    "\n",
    "# Backward pass\n",
    "def backward(X, y, y_pred):\n",
    "    # Derivative of the loss function with respect to y_pred\n",
    "    dL = 2*(y_pred-y)\n",
    "    # Values of the neurons in the hidden layer before applying activation\n",
    "    Ax = (weights_1*X) + bias_1\n",
    "    # Values of the neurons in the hidden layer after applying activation\n",
    "    A = relu(Ax)\n",
    "    # Derivative of the loss function with respect to weight 2\n",
    "    dW2 = torch.mm(A.t(), dL)\n",
    "    # Derivative of the loss function with respect to bias 2\n",
    "    db2 = dL.sum(axis=0)\n",
    "    # Derivative of the loss function with respect to the values of the hidden layer after activation\n",
    "    dA = torch.mm(dL, weights_2.t())\n",
    "    # Derivative of the loss function with respect to the values of the hidden layer before activation\n",
    "    dA[Ax <= 0] = 0\n",
    "    # Derivative of the loss function with respect to weight 1\n",
    "    dW = torch.mm(X.t(), dA)\n",
    "    # Derivative of the loss function with respect to bias 1\n",
    "    db = dA.sum(axis=0)\n",
    "    return dW, db, dW2, db2\n",
    "\n",
    "def optimize(params, grads, lr=0.001):\n",
    "    # Gradient descent over the entire training set\n",
    "    W1, b1, W2, b2 = params\n",
    "    W1 -= lr * grads[0]\n",
    "    W2 -= lr * grads[2]\n",
    "    b1 -= lr * grads[1]\n",
    "    b2 -= lr * grads[3]\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "for i in range(50000): # 50,000 iterations of gradient descent == 50,000 epochs\n",
    "    output = forward(tensor_X)\n",
    "    cur_loss = loss(output, tensor_y)\n",
    "    grads = backward(tensor_X, tensor_y, output)\n",
    "    params = [weights_1, bias_1, weights_2, bias_2]\n",
    "    weights_1, bias_1, weights_2, bias_2 = optimize(params, grads, 1e-4)\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        plt.plot(X, output.numpy(), label=str(i + 1), alpha=0.5)\n",
    "plt.plot(X, y, linestyle='--', c='k', label='real')\n",
    "plt.legend()\n",
    "plt.ylim(y.min(), y.max())\n",
    "print(cur_loss.numpy().mean())\n",
    "\n",
    "```\n",
    "0.002543415\n",
    "\n",
    " <img align=\"right\" src=\"Recources/pic2.png\" height=\"300px\" width=\"580px\"/>  \n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br><br><br><br>\n",
    "\n",
    "\n",
    "# الجزء 2. التصنيف الثنائي باستخدام التفاضل الآلي في PyTorch\n",
    "\n",
    "## توليد العينة وتهيئة معلمات الشبكة العصبية\n",
    "\n",
    "\n",
    "In[4]:\n",
    "```python\n",
    "    X = np.random.randint(2, size=(1000, 2))\n",
    "    \n",
    "    y = (X[:, 0] + X[:, 1]) % 2 # XOR\n",
    "    X = X + np.random.normal(0, scale=0.1, size=X.shape)\n",
    "    #X, y = make_circles(n_samples=1000, noise=0.025)\n",
    "    #X, y = make_moons(n_samples=1000, noise=0.025)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    ####################################################\n",
    "    tensor_X = torch.Tensor(X.reshape(-1, 2))\n",
    "    tensor_y = torch.Tensor(y.reshape(-1, 1))\n",
    "    \n",
    "    HIDDEN_SIZE = 16\n",
    "    # Initialize MLP weights with one hidden layer\n",
    "    weights_1 = ((torch.rand(2, HIDDEN_SIZE)-.5)/10).detach().requires_grad_(True)\n",
    "    bias_1 = torch.zeros(HIDDEN_SIZE, requires_grad=True)\n",
    "    \n",
    "    weights_2 = ((torch.rand(HIDDEN_SIZE, 1)-.5)/10).detach().requires_grad_(True)\n",
    "    bias_2 = torch.zeros(1, requires_grad=True)\n",
    "```\n",
    "\n",
    " <img align=\"right\" src=\"Recources/pic3.png\" height=\"300px\" width=\"580px\"/>  \n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "## تدريب الشبكة العصبية لمهمة التصنيف\n",
    "\n",
    "In[5]:\n",
    "```python\n",
    "    # Define the nonlinearity function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Forward pass\n",
    "def forward(x):\n",
    "    hidden = torch.mm(x, weights_1) + bias_1\n",
    "    hidden_nonlin = sigmoid(hidden)\n",
    "    output = (weights_2.t()*hidden_nonlin).sum(axis=-1, keepdims=True) + bias_2\n",
    "    return sigmoid(output)\n",
    "\n",
    "# Log loss\n",
    "def loss(y_true, y_pred):\n",
    "    return -1 * (y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred)).sum()\n",
    "\n",
    "# Set the learning rate\n",
    "lr = 1e-3\n",
    "# Set the number of iterations\n",
    "iters = 10000\n",
    "params = [weights_1, bias_1, weights_2, bias_2]\n",
    "losses = []\n",
    "\n",
    "for i in range(iters):\n",
    "    output = forward(tensor_X)\n",
    "    lossval = loss(tensor_y, output)\n",
    "    lossval.backward()  # This activates autograd\n",
    "    for w in params:\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * lr  # Update weights\n",
    "        w.grad.zero_()  # Zero out gradients to prevent accumulation over iterations\n",
    "    losses.append(lossval.item())\n",
    "\n",
    "# Output the loss history by iterations\n",
    "plt.plot(losses)\n",
    "\n",
    "```\n",
    "out[5]: [<matplotlib.lines.Line2D at 0x7ff170558b10>]\n",
    "\n",
    "\n",
    " <img align=\"right\" src=\"Recources/pic4.png\" height=\"300px\" width=\"580px\"/>  \n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br><br><br><br>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>التحقق من نتائج التدريب</h2>\n",
    "</div>\n",
    "\n",
    "In[6]:\n",
    "```python\n",
    "X_diff = X.max() - X.min()\n",
    "X_left = X.min() - 0.1 * X_diff\n",
    "X_right = X.max() + 0.1 * X_diff\n",
    "grid = np.arange(X_left, X_right, 0.01)\n",
    "grid_width = grid.size\n",
    "surface = []\n",
    "\n",
    "# Creating points along the grid\n",
    "for x1 in grid:\n",
    "    for x2 in grid:\n",
    "        surface.append((x1, x2))\n",
    "surface = np.array(surface)\n",
    "\n",
    "# Getting predictions for all grid points\n",
    "with torch.no_grad():\n",
    "    Z = forward(torch.Tensor(surface)).detach().numpy()\n",
    "\n",
    "# Reshaping predictions into a 2D array\n",
    "Z = Z.reshape(grid_width, grid_width)\n",
    "xx = surface[:, 0].reshape(grid_width, grid_width)\n",
    "yy = surface[:, 1].reshape(grid_width, grid_width)\n",
    "\n",
    "# Plotting class separation surfaces\n",
    "plt.contourf(xx, yy, Z, alpha=0.5)\n",
    "\n",
    "# Plotting training dataset\n",
    "plt.scatter(X[:, 0], X[:, 1], c=output.detach().numpy() > 0.5)\n",
    "\n",
    "# Setting the display boundaries for the plot\n",
    "plt.xlim(X_left, X_right)\n",
    "plt.ylim(X_left, X_right)\n",
    "\n",
    "```\n",
    "out[6]: (-0.4265555623302785, 1.5671068095642362)\n",
    "\n",
    " <img align=\"right\" src=\"Recources/pic5.png\" height=\"300px\" width=\"580px\"/>  \n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br><br><br><br>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h1>الجزء 3. تصنيف الصور باستخدام مجموعة بيانات CIFAR100</h1>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>تحميل وفك ضغط مجموعة بيانات CIFAR100</h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "In[7]: \n",
    "```python\n",
    "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
    "    !tar -xvzf cifar-100-python.tar.gz\n",
    "```\n",
    "--2022-02-10 21:29:10--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
    "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
    "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 169001437 (161M) [application/x-gzip]\n",
    "Saving to: ‘cifar-100-python.tar.gz’\n",
    "\n",
    "cifar-100-python.ta 100%[===================>] 161.17M  46.1MB/s    in 3.9s    \n",
    "\n",
    "2022-02-10 21:29:14 (41.2 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
    "\n",
    "- cifar-100-python/\n",
    "- cifar-100-python/file.txt~\n",
    "- cifar-100-python/train\n",
    "- cifar-100-python/test\n",
    "- cifar-100-python/meta\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>قراءة بيانات التدريب والاختبار</h2>\n",
    "</div>\n",
    "\n",
    "In[8]:\n",
    "```python\n",
    "    with open('cifar-100-python/train', 'rb') as f:\n",
    "        data_train = pickle.load(f, encoding='latin1')\n",
    "    with open('cifar-100-python/test', 'rb') as f:\n",
    "        data_test = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # Здесь указать ваши классы по варианту!!!\n",
    "    CLASSES = [0, 55, 58]\n",
    "    \n",
    "    train_X = data_train['data'].reshape(-1, 3, 32, 32)\n",
    "    train_X = np.transpose(train_X, [0, 2, 3, 1]) # NCHW -> NHWC\n",
    "    train_y = np.array(data_train['fine_labels'])\n",
    "    mask = np.isin(train_y, CLASSES)\n",
    "    train_X = train_X[mask].copy()\n",
    "    train_y = train_y[mask].copy()\n",
    "    train_y = np.unique(train_y, return_inverse=1)[1]\n",
    "    del data_train\n",
    "    \n",
    "    test_X = data_test['data'].reshape(-1, 3, 32, 32)\n",
    "    test_X = np.transpose(test_X, [0, 2, 3, 1])\n",
    "    test_y = np.array(data_test['fine_labels'])\n",
    "    mask = np.isin(test_y, CLASSES)\n",
    "    test_X = test_X[mask].copy()\n",
    "    test_y = test_y[mask].copy()\n",
    "    test_y = np.unique(test_y, return_inverse=1)[1]\n",
    "    del data_test\n",
    "    Image.fromarray(train_X[50]).resize((256,256))\n",
    "```\n",
    "out[8]:\n",
    " <img align=\"left\" src=\"Recources/pic6.png\" height=\"300px\" width=\"380px\"/>  \n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br><br><br><br>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>إنشاء Pytorch DataLoader</h2>\n",
    "</div>\n",
    "\n",
    "In[9]:\n",
    "```python\n",
    "    batch_size = 128\n",
    "    dataloader = {}\n",
    "    for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
    "                            ['train', 'test']):\n",
    "        tensor_x = torch.Tensor(X)\n",
    "        tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
    "                                         num_classes=len(CLASSES))/1.\n",
    "        dataset = TensorDataset(tensor_x, tensor_y) # создание объекта датасета\n",
    "        dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True) # creating an instance of the DataLoader class\n",
    "    dataloader\n",
    "```\n",
    "out[9]:{'test': <torch.utils.data.dataloader.DataLoader at 0x7ff2823c59d0>,\n",
    "      'train': <torch.utils.data.dataloader.DataLoader at 0x7ff1706411d0>}\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>إنشاء نموذج متعدد الطبقات Pytorch مع طبقة مخفية واحدة</h2>\n",
    "</div>\n",
    "\n",
    "In[10]:\n",
    "```python\n",
    "    class Normalize(nn.Module):\n",
    "        def __init__(self, mean, std):\n",
    "            super(Normalize, self).__init__()\n",
    "            self.mean = torch.tensor(mean)\n",
    "            self.std = torch.tensor(std)\n",
    "    \n",
    "        def forward(self, input):\n",
    "            x = input / 255.0\n",
    "            x = x - self.mean\n",
    "            x = x / self.std\n",
    "            return torch.flatten(x, start_dim=1) # nhwc -> nm\n",
    "    \n",
    "    class Cifar100_MLP(nn.Module):\n",
    "        def __init__(self, hidden_size=32, classes=100):\n",
    "            super(Cifar100_MLP, self).__init__()\n",
    "            # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
    "            self.norm = Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025])\n",
    "            self.seq = nn.Sequential(\n",
    "                nn.Linear(32*32*3, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, classes),\n",
    "            )\n",
    "    \n",
    "        def forward(self, input):\n",
    "            x = self.norm(input)\n",
    "            return self.seq(x)\n",
    "    \n",
    "    HIDDEN_SIZE = 10\n",
    "    model = Cifar100_MLP(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))\n",
    "    model\n",
    "```\n",
    "out[10]:{\n",
    "   Cifar100_MLP(\n",
    "  (norm): Normalize()\n",
    "  (seq): Sequential(\n",
    "    (0): Linear(in_features=3072, out_features=10, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Linear(in_features=10, out_features=3, bias=True)\n",
    "  )\n",
    ")\n",
    "}\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h2>اختيار دالة الخسارة والمُحسِّن لانحدار التدرج</h2>\n",
    "</div>\n",
    "\n",
    "In[11]:\n",
    "```python\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "```\n",
    "\n",
    "## تدريب النموذج حسب العصر\n",
    "\n",
    "In[12]:\n",
    "```python\n",
    "    EPOCHS = 250\n",
    "    steps_per_epoch = len(dataloader['train'])\n",
    "    steps_per_epoch_val = len(dataloader['test'])\n",
    "    for epoch in range(EPOCHS):  # pass through the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dataloader['train'], 0):\n",
    "            # getting a single minibatch; batch is a two-element list of [inputs, labels]\n",
    "            inputs, labels = batch\n",
    "    \n",
    "            # clearing past gradients from the last iteration\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # прямой + обратный проходы + оптимизация\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # statisticians of iwrm calculation\n",
    "            running_loss += loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / steps_per_epoch:.3f}')\n",
    "        running_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # disable automatic differentiation\n",
    "            for i, data in enumerate(dataloader['test'], 0):\n",
    "                inputs, labels = data\n",
    "    \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] val loss: {running_loss / steps_per_epoch_val:.3f}')\n",
    "    print('Обучение закончено')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- [1,    12] loss: 1.015\n",
    "- [1,     3] val loss: 0.921\n",
    "- [2,    12] loss: 0.860\n",
    "- [2,     3] val loss: 0.837\n",
    "- [3,    12] loss: 0.777\n",
    "- [3,     3] val loss: 0.793\n",
    "- [4,    12] loss: 0.721\n",
    "- [4,     3] val loss: 0.743\n",
    "- [5,    12] loss: 0.674\n",
    "- [5,     3] val loss: 0.727\n",
    "- [6,    12] loss: 0.638\n",
    "- [6,     3] val loss: 0.681\n",
    "- [7,    12] loss: 0.612\n",
    "- [7,     3] val loss: 0.658\n",
    "- [8,    12] loss: 0.589\n",
    "- [8,     3] val loss: 0.667\n",
    "- [9,    12] loss: 0.569\n",
    "- [9,     3] val loss: 0.622\n",
    "- [10,    12] loss: 0.552\n",
    "- [10,     3] val loss: 0.632\n",
    "- [11,    12] loss: 0.537\n",
    "- [11,     3] val loss: 0.604\n",
    "- [12,    12] loss: 0.527\n",
    "- [12,     3] val loss: 0.618\n",
    "- [13,    12] loss: 0.513\n",
    "- [13,     3] val loss: 0.578\n",
    "- [14,    12] loss: 0.502\n",
    "- [14,     3] val loss: 0.626\n",
    "- [15,    12] loss: 0.490\n",
    "- [15,     3] val loss: 0.631\n",
    "- [16,    12] loss: 0.482\n",
    "- [16,     3] val loss: 0.577\n",
    "- [17,    12] loss: 0.475\n",
    "- [17,     3] val loss: 0.558\n",
    "- [18,    12] loss: 0.465\n",
    "- [18,     3] val loss: 0.553\n",
    "- [19,    12] loss: 0.459\n",
    "- [19,     3] val loss: 0.556\n",
    "- [20,    12] loss: 0.450\n",
    "- [20,     3] val loss: 0.542\n",
    "- [21,    12] loss: 0.443\n",
    "- [21,     3] val loss: 0.542\n",
    "- [22,    12] loss: 0.438\n",
    "- [22,     3] val loss: 0.585\n",
    "- [23,    12] loss: 0.428\n",
    "- [23,     3] val loss: 0.546\n",
    "- [24,    12] loss: 0.423\n",
    "- [24,     3] val loss: 0.536\n",
    "- [25,    12] loss: 0.416\n",
    "- [25,     3] val loss: 0.528\n",
    "- [26,    12] loss: 0.409\n",
    "- [26,     3] val loss: 0.537\n",
    "- [27,    12] loss: 0.403\n",
    "- [27,     3] val loss: 0.550\n",
    "- [28,    12] loss: 0.399\n",
    "- [28,     3] val loss: 0.512\n",
    "- [29,    12] loss: 0.391\n",
    "- [29,     3] val loss: 0.512\n",
    "- [30,    12] loss: 0.387\n",
    "- [30,     3] val loss: 0.528\n",
    "- [31,    12] loss: 0.381\n",
    "- [31,     3] val loss: 0.515\n",
    "- [32,    12] loss: 0.378\n",
    "- [32,     3] val loss: 0.551\n",
    "- [33,    12] loss: 0.374\n",
    "- [33,     3] val loss: 0.506\n",
    "- [34,    12] loss: 0.368\n",
    "- [34,     3] val loss: 0.519\n",
    "- [35,    12] loss: 0.364\n",
    "- [35,     3] val loss: 0.535\n",
    "- [36,    12] loss: 0.358\n",
    "- [36,     3] val loss: 0.491\n",
    "- [37,    12] loss: 0.355\n",
    "- [37,     3] val loss: 0.529\n",
    "- [38,    12] loss: 0.349\n",
    "- [38,     3] val loss: 0.535\n",
    "- [39,    12] loss: 0.344\n",
    "- [39,     3] val loss: 0.490\n",
    "- [40,    12] loss: 0.341\n",
    "- [40,     3] val loss: 0.544\n",
    "- [41,    12] loss: 0.337\n",
    "- [41,     3] val loss: 0.512\n",
    "- [42,    12] loss: 0.334\n",
    "- [42,     3] val loss: 0.535\n",
    "- [43,    12] loss: 0.329\n",
    "- [43,     3] val loss: 0.490\n",
    "- [44,    12] loss: 0.323\n",
    "- [44,     3] val loss: 0.504\n",
    "- [45,    12] loss: 0.323\n",
    "- [45,     3] val loss: 0.531\n",
    "- [46,    12] loss: 0.317\n",
    "- [46,     3] val loss: 0.536\n",
    "- [47,    12] loss: 0.315\n",
    "- [47,     3] val loss: 0.509\n",
    "- [48,    12] loss: 0.312\n",
    "- [48,     3] val loss: 0.532\n",
    "- [49,    12] loss: 0.306\n",
    "- [49,     3] val loss: 0.525\n",
    "- [50,    12] loss: 0.303\n",
    "- [50,     3] val loss: 0.538\n",
    "- [51,    12] loss: 0.301\n",
    "- [51,     3] val loss: 0.533\n",
    "- [52,    12] loss: 0.297\n",
    "- [52,     3] val loss: 0.536\n",
    "- [53,    12] loss: 0.292\n",
    "- [53,     3] val loss: 0.507\n",
    "- [54,    12] loss: 0.288\n",
    "- [54,     3] val loss: 0.485\n",
    "- [55,    12] loss: 0.288\n",
    "- [55,     3] val loss: 0.487\n",
    "- [56,    12] loss: 0.284\n",
    "- [56,     3] val loss: 0.514\n",
    "- [57,    12] loss: 0.281\n",
    "- [57,     3] val loss: 0.521\n",
    "- [58,    12] loss: 0.276\n",
    "- [58,     3] val loss: 0.525\n",
    "- [59,    12] loss: 0.274\n",
    "- [59,     3] val loss: 0.519\n",
    "- [60,    12] loss: 0.270\n",
    "- [60,     3] val loss: 0.533\n",
    "- [61,    12] loss: 0.270\n",
    "- [61,     3] val loss: 0.535\n",
    "- [62,    12] loss: 0.265\n",
    "- [62,     3] val loss: 0.557\n",
    "- [63,    12] loss: 0.264\n",
    "- [63,     3] val loss: 0.489\n",
    "- [64,    12] loss: 0.260\n",
    "- [64,     3] val loss: 0.502\n",
    "- [65,    12] loss: 0.257\n",
    "- [65,     3] val loss: 0.550\n",
    "- [66,    12] loss: 0.251\n",
    "- [66,     3] val loss: 0.495\n",
    "- [67,    12] loss: 0.252\n",
    "- [67,     3] val loss: 0.485\n",
    "- [68,    12] loss: 0.247\n",
    "- [68,     3] val loss: 0.507\n",
    "- [69,    12] loss: 0.244\n",
    "- [69,     3] val loss: 0.525\n",
    "- [70,    12] loss: 0.241\n",
    "- [70,     3] val loss: 0.526\n",
    "- [71,    12] loss: 0.240\n",
    "- [71,     3] val loss: 0.517\n",
    "- [72,    12] loss: 0.239\n",
    "- [72,     3] val loss: 0.508\n",
    "- [73,    12] loss: 0.236\n",
    "- [73,     3] val loss: 0.495\n",
    "- [74,    12] loss: 0.232\n",
    "- [74,     3] val loss: 0.519\n",
    "- [75,    12] loss: 0.231\n",
    "- [75,     3] val loss: 0.540\n",
    "- [76,    12] loss: 0.227\n",
    "- [76,     3] val loss: 0.517\n",
    "- [77,    12] loss: 0.226\n",
    "- [77,     3] val loss: 0.479\n",
    "- [78,    12] loss: 0.223\n",
    "- [78,     3] val loss: 0.518\n",
    "- [79,    12] loss: 0.223\n",
    "- [79,     3] val loss: 0.529\n",
    "- [80,    12] loss: 0.218\n",
    "- [80,     3] val loss: 0.544\n",
    "- [81,    12] loss: 0.217\n",
    "- [81,     3] val loss: 0.503\n",
    "- [82,    12] loss: 0.214\n",
    "- [82,     3] val loss: 0.519\n",
    "- [83,    12] loss: 0.210\n",
    "- [83,     3] val loss: 0.486\n",
    "- [84,    12] loss: 0.209\n",
    "- [84,     3] val loss: 0.566\n",
    "- [85,    12] loss: 0.207\n",
    "- [85,     3] val loss: 0.482\n",
    "- [86,    12] loss: 0.205\n",
    "- [86,     3] val loss: 0.557\n",
    "- [87,    12] loss: 0.205\n",
    "- [87,     3] val loss: 0.507\n",
    "- [88,    12] loss: 0.201\n",
    "- [88,     3] val loss: 0.528\n",
    "- [89,    12] loss: 0.199\n",
    "- [89,     3] val loss: 0.484\n",
    "- [90,    12] loss: 0.198\n",
    "- [90,     3] val loss: 0.523\n",
    "- [91,    12] loss: 0.196\n",
    "- [91,     3] val loss: 0.534\n",
    "- [92,    12] loss: 0.193\n",
    "- [92,     3] val loss: 0.514\n",
    "- [93,    12] loss: 0.191\n",
    "- [93,     3] val loss: 0.533\n",
    "- [94,    12] loss: 0.189\n",
    "- [94,     3] val loss: 0.546\n",
    "- [95,    12] loss: 0.187\n",
    "- [95,     3] val loss: 0.561\n",
    "- [96,    12] loss: 0.186\n",
    "- [96,     3] val loss: 0.546\n",
    "- [97,    12] loss: 0.183\n",
    "- [97,     3] val loss: 0.501\n",
    "- [98,    12] loss: 0.182\n",
    "- [98,     3] val loss: 0.538\n",
    "- [99,    12] loss: 0.179\n",
    "- [99,     3] val loss: 0.566\n",
    "- [100,   12] loss: 0.177\n",
    "- [100,     3] val loss: 0.530\n",
    "- [101,    12] loss: 0.176\n",
    "- [101,     3] val loss: 0.547\n",
    "- [102,    12] loss: 0.174\n",
    "- [102,     3] val loss: 0.546\n",
    "- [103,    12] loss: 0.173\n",
    "- [103,     3] val loss: 0.543\n",
    "- [104,    12] loss: 0.170\n",
    "- [104,     3] val loss: 0.507\n",
    "- [105,    12] loss: 0.168\n",
    "- [105,     3] val loss: 0.538\n",
    "- [106,    12] loss: 0.167\n",
    "- [106,     3] val loss: 0.539\n",
    "- [107,    12] loss: 0.166\n",
    "- [107,     3] val loss: 0.546\n",
    "- [108,    12] loss: 0.164\n",
    "- [108,     3] val loss: 0.521\n",
    "- [109,    12] loss: 0.163\n",
    "- [109,     3] val loss: 0.587\n",
    "- [110,    12] loss: 0.159\n",
    "- [110,     3] val loss: 0.541\n",
    "- [111,    12] loss: 0.158\n",
    "- [111,     3] val loss: 0.595\n",
    "- [112,    12] loss: 0.156\n",
    "- [112,     3] val loss: 0.560\n",
    "- [113,    12] loss: 0.155\n",
    "- [113,     3] val loss: 0.522\n",
    "- [114,    12] loss: 0.154\n",
    "- [114,     3] val loss: 0.583\n",
    "- [115,    12] loss: 0.152\n",
    "- [115,     3] val loss: 0.564\n",
    "- [116,    12] loss: 0.152\n",
    "- [116,     3] val loss: 0.485\n",
    "- [117,    12] loss: 0.149\n",
    "- [117,     3] val loss: 0.538\n",
    "- [118,    12] loss: 0.148\n",
    "- [118,     3] val loss: 0.606\n",
    "- [119,    12] loss: 0.147\n",
    "- [119,     3] val loss: 0.526\n",
    "- [120,    12] loss: 0.145\n",
    "- [120,     3] val loss: 0.566\n",
    "- [121,    12] loss: 0.144\n",
    "- [121,     3] val loss: 0.592\n",
    "- [122,    12] loss: 0.142\n",
    "- [122,     3] val loss: 0.530\n",
    "- [123,    12] loss: 0.141\n",
    "- [123,     3] val loss: 0.563\n",
    "- [124,    12] loss: 0.138\n",
    "- [124,     3] val loss: 0.563\n",
    "- [125,    12] loss: 0.137\n",
    "- [125,     3] val loss: 0.519\n",
    "- [126,    12] loss: 0.136\n",
    "- [126,     3] val loss: 0.632\n",
    "- [127,    12] loss: 0.136\n",
    "- [127,     3] val loss: 0.541\n",
    "- [128,    12] loss: 0.136\n",
    "- [128,     3] val loss: 0.572\n",
    "- [129,    12] loss: 0.133\n",
    "- [129,     3] val loss: 0.591\n",
    "- [130,    12] loss: 0.133\n",
    "- [130,     3] val loss: 0.572\n",
    "- [131,    12] loss: 0.130\n",
    "- [131,     3] val loss: 0.543\n",
    "- [132,    12] loss: 0.128\n",
    "- [132,     3] val loss: 0.599\n",
    "- [133,    12] loss: 0.128\n",
    "- [133,     3] val loss: 0.531\n",
    "- [134,    12] loss: 0.126\n",
    "- [134,     3] val loss: 0.601\n",
    "- [135,    12] loss: 0.127\n",
    "- [135,     3] val loss: 0.607\n",
    "- [136,    12] loss: 0.123\n",
    "- [136,     3] val loss: 0.627\n",
    "- [137,    12] loss: 0.123\n",
    "- [137,     3] val loss: 0.574\n",
    "- [138,    12] loss: 0.122\n",
    "- [138,     3] val loss: 0.614\n",
    "- [139,    12] loss: 0.121\n",
    "- [139,     3] val loss: 0.556\n",
    "- [140,    12] loss: 0.119\n",
    "- [140,     3] val loss: 0.589\n",
    "- [141,    12] loss: 0.118\n",
    "- [141,     3] val loss: 0.587\n",
    "- [142,    12] loss: 0.118\n",
    "- [142,     3] val loss: 0.593\n",
    "- [143,    12] loss: 0.118\n",
    "- [143,     3] val loss: 0.606\n",
    "- [144,    12] loss: 0.115\n",
    "- [144,     3] val loss: 0.631\n",
    "- [145,    12] loss: 0.114\n",
    "- [145,     3] val loss: 0.557\n",
    "- [146,    12] loss: 0.113\n",
    "- [146,     3] val loss: 0.640\n",
    "- [147,    12] loss: 0.113\n",
    "- [147,     3] val loss: 0.590\n",
    "- [148,    12] loss: 0.111\n",
    "- [148,     3] val loss: 0.576\n",
    "- [149,    12] loss: 0.111\n",
    "- [149,     3] val loss: 0.596\n",
    "- [150,    12] loss: 0.110\n",
    "- [150,     3] val loss: 0.571\n",
    "- [151,    12] loss: 0.109\n",
    "- [151,     3] val loss: 0.584\n",
    "- [152,    12] loss: 0.107\n",
    "- [152,     3] val loss: 0.596\n",
    "- [153,    12] loss: 0.107\n",
    "- [153,     3] val loss: 0.580\n",
    "- [154,    12] loss: 0.106\n",
    "- [154,     3] val loss: 0.598\n",
    "- [155,    12] loss: 0.105\n",
    "- [155,     3] val loss: 0.624\n",
    "- [156,    12] loss: 0.103\n",
    "- [156,     3] val loss: 0.581\n",
    "- [157,    12] loss: 0.103\n",
    "- [157,     3] val loss: 0.606\n",
    "- [158,    12] loss: 0.102\n",
    "- [158,     3] val loss: 0.569\n",
    "- [159,    12] loss: 0.101\n",
    "- [159,     3] val loss: 0.556\n",
    "- [160,    12] loss: 0.100\n",
    "- [160,     3] val loss: 0.582\n",
    "- [161,    12] loss: 0.100\n",
    "- [161,     3] val loss: 0.614\n",
    "- [162,    12] loss: 0.099\n",
    "- [162,     3] val loss: 0.615\n",
    "- [163,    12] loss: 0.098\n",
    "- [163,     3] val loss: 0.559\n",
    "- [164,    12] loss: 0.097\n",
    "- [164,     3] val loss: 0.590\n",
    "- [165,    12] loss: 0.095\n",
    "- [165,     3] val loss: 0.596\n",
    "- [166,    12] loss: 0.095\n",
    "- [166,     3] val loss: 0.663\n",
    "- [167,    12] loss: 0.094\n",
    "- [167,     3] val loss: 0.666\n",
    "- [168,    12] loss: 0.093\n",
    "- [168,     3] val loss: 0.591\n",
    "- [169,    12] loss: 0.093\n",
    "- [169,     3] val loss: 0.627\n",
    "- [170,    12] loss: 0.091\n",
    "- [170,     3] val loss: 0.598\n",
    "- [171,    12] loss: 0.090\n",
    "- [171,     3] val loss: 0.683\n",
    "- [172,    12] loss: 0.090\n",
    "- [172,     3] val loss: 0.652\n",
    "- [173,    12] loss: 0.090\n",
    "- [173,     3] val loss: 0.601\n",
    "- [174,    12] loss: 0.089\n",
    "- [174,     3] val loss: 0.624\n",
    "- [175,    12] loss: 0.088\n",
    "- [175,     3] val loss: 0.649\n",
    "- [176,    12] loss: 0.088\n",
    "- [176,     3] val loss: 0.624\n",
    "- [177,    12] loss: 0.088\n",
    "- [177,     3] val loss: 0.656\n",
    "- [178,    12] loss: 0.086\n",
    "- [178,     3] val loss: 0.645\n",
    "- [179,    12] loss: 0.085\n",
    "- [179,     3] val loss: 0.614\n",
    "- [180,    12] loss: 0.084\n",
    "- [180,     3] val loss: 0.650\n",
    "- [181,    12] loss: 0.085\n",
    "- [181,     3] val loss: 0.581\n",
    "- [182,    12] loss: 0.083\n",
    "- [182,     3] val loss: 0.594\n",
    "- [183,    12] loss: 0.082\n",
    "- [183,     3] val loss: 0.603\n",
    "- [184,    12] loss: 0.082\n",
    "- [184,     3] val loss: 0.650\n",
    "- [185,    12] loss: 0.082\n",
    "- [185,     3] val loss: 0.647\n",
    "- [186,    12] loss: 0.082\n",
    "- [186,     3] val loss: 0.646\n",
    "- [187,    12] loss: 0.081\n",
    "- [187,     3] val loss: 0.580\n",
    "- [188,    12] loss: 0.079\n",
    "- [188,     3] val loss: 0.676\n",
    "- [189,    12] loss: 0.079\n",
    "- [189,     3] val loss: 0.597\n",
    "- [190,    12] loss: 0.078\n",
    "- [190,     3] val loss: 0.620\n",
    "- [191,    12] loss: 0.077\n",
    "- [191,     3] val loss: 0.655\n",
    "- [192,    12] loss: 0.077\n",
    "- [192,     3] val loss: 0.590\n",
    "- [193,    12] loss: 0.076\n",
    "- [193,     3] val loss: 0.668\n",
    "- [194,    12] loss: 0.075\n",
    "- [194,     3] val loss: 0.686\n",
    "- [195,    12] loss: 0.075\n",
    "- [195,     3] val loss: 0.628\n",
    "- [196,    12] loss: 0.074\n",
    "- [196,     3] val loss: 0.627\n",
    "- [197,    12] loss: 0.074\n",
    "- [197,     3] val loss: 0.625\n",
    "- [198,    12] loss: 0.074\n",
    "- [198,     3] val loss: 0.620\n",
    "- [199,    12] loss: 0.073\n",
    "- [199,     3] val loss: 0.623\n",
    "- [200,    12] loss: 0.072\n",
    "- [200,     3] val loss: 0.600\n",
    "- [201,    12] loss: 0.072\n",
    "- [201,     3] val loss: 0.624\n",
    "- [202,    12] loss: 0.070\n",
    "- [202,     3] val loss: 0.700\n",
    "- [203,    12] loss: 0.070\n",
    "- [203,     3] val loss: 0.709\n",
    "- [204,    12] loss: 0.070\n",
    "- [204,     3] val loss: 0.681\n",
    "- [205,    12] loss: 0.069\n",
    "- [205,     3] val loss: 0.683\n",
    "- [206,    12] loss: 0.069\n",
    "- [206,     3] val loss: 0.689\n",
    "- [207,    12] loss: 0.068\n",
    "- [207,     3] val loss: 0.627\n",
    "- [208,    12] loss: 0.068\n",
    "- [208,     3] val loss: 0.615\n",
    "- [209,    12] loss: 0.068\n",
    "- [209,     3] val loss: 0.684\n",
    "- [210,    12] loss: 0.067\n",
    "- [210,     3] val loss: 0.610\n",
    "- [211,    12] loss: 0.066\n",
    "- [211,     3] val loss: 0.670\n",
    "- [212,    12] loss: 0.067\n",
    "- [212,     3] val loss: 0.685\n",
    "- [213,    12] loss: 0.065\n",
    "- [213,     3] val loss: 0.678\n",
    "- [214,    12] loss: 0.066\n",
    "- [214,     3] val loss: 0.683\n",
    "- [215,    12] loss: 0.065\n",
    "- [215,     3] val loss: 0.622\n",
    "- [216,    12] loss: 0.063\n",
    "- [216,     3] val loss: 0.658\n",
    "- [217,    12] loss: 0.063\n",
    "- [217,     3] val loss: 0.691\n",
    "- [218,    12] loss: 0.063\n",
    "- [218,     3] val loss: 0.661\n",
    "- [219,    12] loss: 0.063\n",
    "- [219,     3] val loss: 0.696\n",
    "- [220,    12] loss: 0.062\n",
    "- [220,     3] val loss: 0.602\n",
    "- [221,    12] loss: 0.061\n",
    "- [221,     3] val loss: 0.665\n",
    "- [222,    12] loss: 0.062\n",
    "- [222,     3] val loss: 0.679\n",
    "- [223,    12] loss: 0.061\n",
    "- [223,     3] val loss: 0.650\n",
    "- [224,    12] loss: 0.061\n",
    "- [224,     3] val loss: 0.694\n",
    "- [225,    12] loss: 0.060\n",
    "- [225,     3] val loss: 0.654\n",
    "- [226,    12] loss: 0.060\n",
    "- [226,     3] val loss: 0.670\n",
    "- [227,    12] loss: 0.059\n",
    "- [227,     3] val loss: 0.687\n",
    "- [228,    12] loss: 0.059\n",
    "- [228,     3] val loss: 0.666\n",
    "- [229,    12] loss: 0.059\n",
    "- [229,     3] val loss: 0.734\n",
    "- [230,    12] loss: 0.058\n",
    "- [230,     3] val loss: 0.729\n",
    "- [231,    12] loss: 0.057\n",
    "- [231,     3] val loss: 0.701\n",
    "- [232,    12] loss: 0.057\n",
    "- [232,     3] val loss: 0.627\n",
    "- [233,    12] loss: 0.056\n",
    "- [233,     3] val loss: 0.642\n",
    "- [234,    12] loss: 0.056\n",
    "- [234,     3] val loss: 0.644\n",
    "- [235,    12] loss: 0.056\n",
    "- [235,     3] val loss: 0.684\n",
    "- [236,    12] loss: 0.056\n",
    "- [236,     3] val loss: 0.684\n",
    "- [237,    12] loss: 0.055\n",
    "- [237,     3] val loss: 0.673\n",
    "- [238,    12] loss: 0.055\n",
    "- [238,     3] val loss: 0.684\n",
    "- [239,    12] loss: 0.054\n",
    "- [239,     3] val loss: 0.723\n",
    "- [240,    12] loss: 0.054\n",
    "- [240,     3] val loss: 0.747\n",
    "- [241,    12] loss: 0.054\n",
    "- [241,     3] val loss: 0.702\n",
    "- [242,    12] loss: 0.053\n",
    "- [242,     3] val loss: 0.742\n",
    "- [243,    12] loss: 0.053\n",
    "- [243,     3] val loss: 0.641\n",
    "- [244,    12] loss: 0.053\n",
    "- [244,     3] val loss: 0.685\n",
    "- [245,    12] loss: 0.052\n",
    "- [245,     3] val loss: 0.615\n",
    "- [246,    12] loss: 0.052\n",
    "- [246,     3] val loss: 0.753\n",
    "- [247,    12] loss: 0.051\n",
    "- [247,     3] val loss: 0.744\n",
    "- [248,    12] loss: 0.052\n",
    "- [248,     3] val loss: 0.696\n",
    "- [249,    12] loss: 0.051\n",
    "- [249,     3] val loss: 0.681\n",
    "- [250,    12] loss: 0.051\n",
    "- [250,     3] val loss: 0.706\n",
    "\n",
    "Обучение закончено\n",
    "## التحقق من جودة النموذج من قبل فئة في تدريب واختبار العينات\n",
    "\n",
    "In[13]:\n",
    "\n",
    "```python\n",
    "    for part in ['train', 'test']:\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad(): # disable automatic differentiation\n",
    "            for i, data in enumerate(dataloader[part], 0):\n",
    "                inputs, labels = data\n",
    "    \n",
    "                outputs = model(inputs).detach().numpy()\n",
    "                y_pred.append(outputs)\n",
    "                y_true.append(labels.numpy())\n",
    "            y_true = np.concatenate(y_true)\n",
    "            y_pred = np.concatenate(y_pred)\n",
    "            print(part)\n",
    "            print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1),\n",
    "                                        digits=4, target_names=list(map(str, CLASSES))))\n",
    "            print('-'*50)\n",
    "\n",
    "```\n",
    "train\n",
    "\n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0     1.0000    0.9900    0.9950       500\n",
    "          55     0.9881    1.0000    0.9940       500\n",
    "          58     0.9980    0.9960    0.9970       500\n",
    "\n",
    "    accuracy                         0.9953      1500\n",
    "    macro avg     0.9954    0.9953    0.9953      1500\n",
    "    weighted avg     0.9954    0.9953    0.9953      1500\n",
    "\n",
    "---\n",
    "test\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.8174    0.9400    0.8744       100\n",
    "          55     0.7158    0.6800    0.6974       100\n",
    "          58     0.6889    0.6200    0.6526       100\n",
    "\n",
    "    accuracy                         0.7467       300\n",
    "    macro avg     0.7407    0.7467    0.7415       300\n",
    "    weighted avg     0.7407    0.7467    0.7415       300\n",
    "\n",
    "---\n",
    "\n",
    "## التصور المقاييس\n",
    "In[13]:\n",
    "\n",
    "```python\n",
    "    weights = list(model.parameters())[0].detach().numpy()\n",
    "    print(weights.shape)\n",
    "    fig, ax = plt.subplots(1, weights.shape[0], figsize=(3*weights.shape[0], 3))\n",
    "    for i, ω in enumerate(weights):\n",
    "        ω = ω.reshape(32, 32, 3)\n",
    "        ω -= np.percentile(ω, 1, axis=[0, 1])\n",
    "        ω /= np.percentile(ω, 99, axis=[0, 1])\n",
    "        ω = np.clip(ω, 0, 1) \n",
    "        ax[i].imshow(ω)\n",
    "```\n",
    "(10, 3072)\n",
    "\n",
    "\n",
    "<div dir=\"rtl\" style=\"margin-top: 70px;\">\n",
    "    <img align=\"right\" src=\"Recources/pic7.png\" height=\"140px\" width=\"620px\"/>  \n",
    "    <hr style=\"margin-top: 70px; margin-bottom: 70px;\"> \n",
    "</div>\n",
    "\n",
    "<br><br><br> <br><br><br> <br><br><br> <br><br>\n",
    "\n",
    "\n",
    "# وصف  طرق المكتبة\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    <h3>الأساليب والدوال في مكتبة NumPy:</h3>\n",
    "</div>\n",
    "\n",
    "(للحصول على مزيد من المعلومات ، راجع الوثائق https://numpy.org/doc/1.22/reference/index.html)\n",
    "\n",
    "<div dir=\"rtl\">* __np.array__ - إنشاء مصفوفة من قائمة أو مصفوفة أخرى</div>\n",
    "<div dir=\"rtl\">* __np.shape__ - يعرض أبعاد المصفوفة متعددة الأبعاد (أي لمصفوفة 2×2 سيكون الناتج هو مجموعة (2، 2))</div>\n",
    "<div dir=\"rtl\">* __np.size__ - يعرض عدد العناصر في المصفوفة (أي لمصفوفة 2×2 سيكون الناتج 4)</div>\n",
    "<div dir=\"rtl\">* __np.uint8__، __np.int16__، __np.int64__، __np.float32__ - تحويل المصفوفة إلى نوع جديد، مع تخصيص مساحة في الذاكرة للمصفوفة الجديدة من النوع المختار. العدد بعد النوع يحدد عدد البتات المستخدمة لتخزين عنصر واحد من المصفوفة. غالبًا ما يستخدم النوع الاقتصادي uint8 - وهو نوع بيانات صحيح غير موقّع من 8 بت (نطاق الأعداد 0-255) لتخزين الصور</div>\n",
    "<div dir=\"rtl\">* __np.ones__، __np.zeros__ - إنشاء مصفوفات مُعبأة مسبقًا إما بالأحادية أو بالصفر. يتم تمرير قائمة أو مجموعة كوسيط لتحديد الأبعاد المطلوبة. على سبيل المثال <code>np.ones((10,))</code> ستقوم بإنشاء متجه مكون من 10 أعداد أحادية. و <code>np.zeros((32, 32, 3))</code> ستقوم بإنشاء مصفوفة ثنائية الأبعاد بدقة 32×32 بكسل مع 3 قنوات. يُستخدم عمليًا للتحقق من بنية النموذج في الاتجاه المباشر</div>\n",
    "<div dir=\"rtl\">* __np.arange__ - إنشاء مصفوفة مُعبأة مسبقًا بشكل متزايد من خلال المتتالية الحسابية من الوسيط الأول إلى الثاني (غير مشمول) بخطوة تحدد بالوسيط الثالث. يمكن استبعاد الوسيطين الأول والثالث، وفي هذه الحالة يتم الحصول على كتابة مضغوطة <code>np.arange(3)</code> => [0، 1، 2]</div>\n",
    "<div dir=\"rtl\">* __np.repeat__ - تكرار عناصر المصفوفة بعدد محدد يحدد بالوسيط الأول. وبالتالي، بالنسبة لمصفوفة <code>arr = [0، 1]</code>، <code>arr.repeat(2)</code> ستعيد [0، 0، 1، 1]</div>\n",
    "<div dir=\"rtl\">* __np.exp__ - تطبيق عملية القوة على كل عنصر في المصفوفة</div>\n",
    "<div dir=\"rtl\">* __np.random.normal__ - توليد مصفوفة مُعبأة بقيم عشوائية طبيعية مع انحراف معياري تحدده الوسيط scale ومتوسط يساوي الوسيط mean. يتم تحديد عدد العناصر في المصفوفة بواسطة عدد أو قائمة يتم تمريرها للوسيط size.</div>\n",
    "<div dir=\"rtl\">* __np.random.randint__ - توليد مصفوفة مُعبأة بأعداد صحيحة عشوائية ضمن نطاق يحدد بطريقة مماثلة لـ __np.arange__. يتم تحديد عدد العناصر في المصفوفة بواسطة عدد أو قائمة يتم تمريرها للوسيط size.</div>\n",
    "<div dir=\"rtl\">* __np.reshape__ - تغيير أبعاد المصفوفة متعددة الأبعاد وفقًا لعدد العناصر. يتم تمرير مصفوفة متعددة الأبعاد كوسيط، بالإضافة إلى قائمة أو مجموعة مع الأبعاد الجديدة. على سبيل المثال `np.reshape([0، 1، 2، 3]، (2،2))` ستقوم بإنشاء مصفوفة ثنائية الأبعاد بحجم 2×2. في هذه الحالة، لا يتم تخصيص مصفوفة جديدة في الذاكرة، بل يتم تغيير طريقة التجوال فيها. يمكن أيضًا استدعاء الدالة بالطريقة التالية: `arr.reshape(2، 2)`. لاحظ عدم وجود أقواس إضافية. إذا تم استبدال رقم محدد بـ -1، سيتم حساب الأبعاد تلقائيًا. يُستخدم عمليًا لتسوية الصور في شكل مصفوفة أحادية البعد: `X.reshape(-1، 3072)` # [100، 32، 32، 3] -> [100، 3072]</div>\n",
    "<div dir=\"rtl\">* __np.transpose__ - إعادة تسمية محاور المصفوفة متعددة الأبعاد. في العمل مع الصور، يوجد تنسيقان هما NHWC و NCHW (N - عدد الصور في المصفوفة، C - عدد القنوات، H - الارتفاع، W - العرض). يتم تمرير مصفوفة متعددة الأبعاد كوسيط، بالإضافة إلى قائمة أو مجموعة مع الترتيب الجديد للمحاور. على سبيل المثال `np.transpose([[0، 1، 2، 3]]، (1،0))` ستقوم بإنشاء متجه عمودي ثنائي الأبعاد [[[0]، [1]، [2]، [3]]. لاحظ أن عد المحاور يبدأ من 0. يُستخدم عمليًا لتحويل NHWC إلى NCHW والعكس. في الحالة الأولى، تبقى المحور 0 N في مكانه الأول، بينما يتم تحريك المحورين الأول والثاني H و W إلى اليمين بمكان واحد، ويُوضع المحور الثالث - C في المكان الثاني. أي سنحصل على الترتيب التالي: [0، 3، 1، 2]</div>\n",
    "<div dir=\"rtl\">* __np.isin__ - مشابه لمشغل SQL IN، فحص العناصر واحدًا تلو الآخر إذا كانت المصفوفة تنتمي إلى مجموعة. `np.isin([0، 2، 1]، [2، 3])` ستعيد [False، True، False]</div>\n",
    "<div dir=\"rtl\">* __الفهرسة__ - اختيار مصفوفة فرعية أو شريحة من المصفوفة يتم باستخدام الأقواس المربعة []. إذا كان `arr = np.array([2، 1، 0])`، فإن `arr[0]` ستعيد العنصر الأول. `arr[[0، 1]]` - الوصول بواسطة الفهرس، `arr[[True، False، True]]` - الوصول بواسطة القناع البولي. لاحظ أن الوصول بواسطة الفهرس ليس بالضرورة أن يتوافق مع أبعاد المصفوفة، على عكس الوصول بواسطة القناع. من العملي تسجيل قيم القناع في متغير منفصل. لاختيار عمود معين في مصفوفة متعددة الأبعاد، يتم استخدام بناء الجملة الشرائحي [:، k]، حيث k هو رقم العمود. إذا كانت k تساوي -1، فإن العمود الأخير أو العنصر يتم استخدامه. على سبيل المثال، بالنسبة للمصفوفة `arr = np.array([[0، 1]، [2، 3]، [4، 5])` التعبير `arr[:, 0]` سيعيد المصفوفة [0، 2، 4]. نظرًا لاستخدام فهرس الشرائح (بناء الجملة القياسي في Python)، يمكن أيضًا تنفيذ شرائح للمصفوفات متعددة الأبعاد. بالنسبة للمثال السابق، `arr[1:2، 0:1]` ستعيد [[2]]</div>\n",
    "<div dir=\"rtl\">* __np.unique__ - مشابه لـ SELECT DISTINCT في SQL. عند استخدام المعلمات الافتراضية، يعيد مصفوفة فرعية أحادية البعد تحتوي على عناصر فريدة. إذا تم تحديد العلم __return_inverse__، فسيتم إرجاع مصفوفة بأرقام الفهرس للعناصر الفريدة. في الأساس، يتم تنفيذ الترميز التسمياتي</div>\n",
    "<div dir=\"rtl\">* __np.concatenate__ - دمج مصفوفة متعددة الأبعاد على طول المحور المحدد. يتم تحديد رقم المحور من خلال الوسيط __axis__. على سبيل المثال، يمكن استخدامه لدمج ميزات متعددة أو مجموعات بيانات متعددة. في سياق الصور، يمكن استخدامه لدمج أو لصق صور متعددة في صورة واحدة بشكل عمودي أو أفقي. في سياق الصوت - دمج مسارين صوتيين.</div>\n",
    "<div dir=\"rtl\">* __np.max__، __np.min__ - تعيد العناصر القصوى والدنيا للمصفوفة على طول المحور المحدد، على التوالي. إذا لم يتم تحديد رقم المحور، يتم إرجاع رقم. يتم تحديد رقم المحور من خلال الوسيط __axis__. إذا تم تحديد -1، فيفترض أن يتم استخدام الرقم الأخير للمحور. يمكن أيضًا استدعاء الدالة كطريقة للمصفوفة متعددة الأبعاد: `arr.max()`</div>\n",
    "<div dir=\"rtl\">* __np.argmax__ - يعيد فهرس العنصر الأقصى للمصفوفة على طول المحور المحدد. إذا لم يتم تحديد رقم المحور، يتم إرجاع أول فهرس يتوافق مع القيمة القصوى في المصفوفة، أي رقم واحد. يتم تحديد رقم المحور من خلال الوسيط __axis__. إذا تم تحديد -1، فيفترض أن يتم استخدام الرقم الأخير للمحور. في الممارسة العملية، يتم استخدامه لحساب مقياس دقة نموذج الإجابات الصحيحة (Accuracy). يمكن أيضًا استدعاء الدالة كطريقة للمصفوفة متعددة الأبعاد: `arr.argmax(axis=-1)`</div>\n",
    "`\n",
    "\n",
    "<div dir=\"rtl\"><h3>طرق ووظائف Pickle</h3></div>\n",
    "\n",
    "(documation: https://docs.python.org/3/library/pickle.html)\n",
    "\n",
    "<div dir=\"rtl\">* __pickle.dump__ - تسلسل هيكل بيانات Python. يتم تمرير الهيكل نفسه كمعامل أول، وFileObject كمعامل ثاني. يجب أن يتم فتح FileObject في وضع كتابة البايتات (wb). يمكن تحديد ترميز البايت (big endian/ little endian). هذا يسمح بتخزين هياكل البيانات القياسية، بما في ذلك مصفوفات NumPy، بشكل دائم على الوسائط.</div>\n",
    "<div dir=\"rtl\">* __pickle.load__ - فك تسلسل هيكل بيانات Python. يتم تمرير FileObject كمعامل أول. يجب أن يتم فتح FileObject في وضع قراءة البايتات (rb). يمكن تحديد ترميز البايت (big endian/ little endian). هذا يسمح بتحميل الهياكل التي تم تخزينها سابقاً، مما يمكن أن يكون مفيداً إذا كان إعدادها يستغرق وقتاً طويلاً (مثل إعداد معلمات نموذج التعلم العميق).</div>\n",
    "\n",
    "<div dir=\"rtl\">### طرق ووظائف Sklearn</div>\n",
    "<div dir=\"rtl\">(التوثيق: https://scikit-learn.org/stable/modules/classes.html)</div>\n",
    "\n",
    "<div dir=\"rtl\">* __datasets.make_circles__، __datasets.make_moons__ - إنشاء مجموعة بيانات تدريب اصطناعية لمهام التصنيف. تُرجع X كمصفوفة ثنائية الأبعاد بعدد الأمثلة والميزات (2 ميزات)، بالإضافة إلى مصفوفة أحادية الأبعاد بتسميات الفئات (0 أو 1).</div>\n",
    "\n",
    "<div dir=\"rtl\">* __metrics.classification_report__ - تنشئ تقريراً نصياً يعرض المقاييس الرئيسية للتصنيف (دقة الإجابة، الاسترجاع، الدقة، مقياس f1). يُمرر مصفوفة العلامات الحقيقية كمعامل أول، ومصفوفة العلامات المتوقعة من النموذج كمعامل ثاني. المعاملات الإضافية المفيدة: digits - عدد الأرقام بعد الفاصلة (افتراضي 2)، output_dict - تُرجع قاموساً يحتوي على المقاييس المحسوبة بدلاً من سلسلة نصية، sample_weight - تحسب المقاييس المرجحة بناءً على وزن كل مثال.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __metrics.confusion_matrix__ - تحسب مصفوفة الارتباك للنموذج لتقييم دقة التصنيف. تحتوي مصفوفة الارتباك للنموذج المثالي على قيم فقط على القطر الرئيسي. يمكن استخدامها لحساب جميع مقاييس التصنيف التقليدية (دقة الإجابة، الاسترجاع، الدقة، النوعية، مقياس f1).</div>\n",
    "\n",
    "<div dir=\"rtl\"><h3>طرق ووظائف PIL</h3></div>\n",
    "\n",
    "(documation: https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "<div dir=\"rtl\">* __Image.fromarray__ - ينشئ كائن Image من مصفوفة ثنائية الأبعاد أو مصفوفة ثنائية الأبعاد تحتوي على قنوات. غالبًا ما يظهر خطأ إذا لم يكن نوع البيانات uint8. قد يظهر خطأ أيضًا عند محاولة إنشاء صورة بالأبيض والأسود من صورة بأبعاد (W, H, 1). لاسترجاع المصفوفة من كائن Image، يمكن تحويلها إلى مصفوفة NumPy، على سبيل المثال np.array(img).</div>\n",
    "\n",
    "<div dir=\"rtl\">* __Image.resize__ - يغيّر دقة الصورة باستخدام الاستيفاء. يُحدد كأول معامل قائمة تحتوي على العرض والارتفاع الجديدين للصورة. يمكن أيضًا تحديد نوع الاستيفاء من خلال معامل resample. القيم المدعومة: PIL.Image.NEAREST، PIL.Image.BOX، PIL.Image.BILINEAR، PIL.Image.HAMMING، PIL.Image.BICUBIC، PIL.Image.LANCZOS. يستخدم استيفاء بيكوبيكي بشكل افتراضي.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __Image.convert__ - يحول الصورة من صيغة ألوان إلى أخرى. تُحدد صيغة الألوان الجديدة كسلسلة نصية، حيث L للأبيض والأسود، LA للأبيض والأسود مع الشفافية، RGB للصيغة القياسية ذات 3 قنوات، RGBA للصيغة القياسية مع 3 قنوات لون وقناة شفافية، HSV لتمثيل ألوان بديل، وهكذا.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __Image.open__ - يقرأ الصورة من المسار المحدد كصيغة نصية أو كائن ملف. عند إنشاء مجموعة بيانات، قد يحدد التنسيق بشكل غير صحيح (مثل L بدلاً من RGB)، لذا يُفضل تحويل التنسيق مباشرةً باستخدام دالة convert بعد الفتح.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __Image.save__ - يحفظ الصورة في المسار المحدد كصيغة نصية أو كائن ملف. إذا كان المسار كائن ملف، فيجب أيضًا تحديد صيغة الصورة في معامل format، مثل 'PNG' أو 'JPEG'.</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\"><h3> Matplotlib طرق ووظائف PIL</h3></div>\n",
    "\n",
    "(documation: https://matplotlib.org/stable/api/index.html)\n",
    "\n",
    "الاختصارات المقبولة:\n",
    "<div dir=\"rtl\">\n",
    "* matplotlib.pyplot - plt\n",
    "</div>\n",
    "\n",
    "طُرق:\n",
    "\n",
    "<div dir=\"rtl\">* __plt.plot__ - يرسم رسمًا بيانيًا حسب النقاط ويقوم بتوصيلها بخط. يُمرر كأول وسيط إحداثيات x، وكثاني وسيط إحداثيات y. إذا لم يتم تمرير الوسيط الثاني، سيتم اعتبار إحداثيات x كـ y، وسيتم استخدام عدد عناصر المصفوفة كإحداثيات x. هناك بعض المعاملات الإضافية المفيدة: linestyle - نوع الخط المعروض ('--'، '-'، '-.'، إلخ)، color - لون الخط ('k' - أسود، 'r' - أحمر، 'white' - أبيض، إلخ)، alpha - شفافية الخط، قيمة من 0 (الخط غير مرئي) إلى 1 (بدون شفافية)، label - التسمية النصية لهذا الرسم.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.scatter__ - يرسم الرسم البياني حسب النقاط دون توصيلها بخطوط. يُمرر كأول وسيط إحداثيات x، وكثاني وسيط إحداثيات y. إذا لم يتم تمرير الوسيط الثاني، سيتم اعتبار إحداثيات x كـ y، وسيتم استخدام عدد عناصر المصفوفة كإحداثيات x. هناك بعض المعاملات الإضافية المفيدة: s - حجم النقاط، color - لون النقاط ('k' - أسود، 'r' - أحمر، 'white' - أبيض، إلخ)، alpha - شفافية النقاط، قيمة من 0 (النقطة غير مرئية) إلى 1 (بدون شفافية)، label - التسمية النصية لهذا الرسم.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.contourf__ - يرسم خطوط كفاف مملوءة لتحديد الحدود الفاصلة.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.show__ - عرض إجباري للرسم البياني، ويمكن استخدامه لعرض عدة رسوم بيانية في نفس الكود.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.legend__ - يعرض التسميات التي تم تحديدها مسبقًا للرسوم البيانية.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.xlim__ - يحدّد نطاق إحداثيات x من الوسيط الأول إلى الوسيط الثاني. افتراضيًا، يتم تعيين نطاق المحور الأفقي تلقائيًا بناءً على البيانات المستخدمة. يُستخدم هذا الأسلوب لتحديد نطاق القيم على المحور الأفقي يدويًا.</div>\n",
    "\n",
    "<div dir=\"rtl\">* __plt.ylim__ - مشابهة لـ __plt.xlim__، لكنها للمحور العمودي.</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
