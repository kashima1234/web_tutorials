<a href="https://colab.research.google.com/github/iu5git/Deep-learning/blob/main/notebooks/Lab1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# العمل المخبري رقم 1

## المهمة

يجب التعرف على إطار عمل التعلم الآلي PyTorch وتنفيذ ثلاث مهام:
1. الانحدار وفقًا لنظرية التقريب الشامل، التفاضل اليدوي
2. التصنيف الثنائي باستخدام التفاضل التلقائي في PyTorch
3. تدريب شبكة عصبية كاملة الاتصال لتصنيف 3 فئات من الصور من مجموعة بيانات CIFAR100 وفقًا للمثال المحدد ثم تحسين الدقة على مجموعة الاختبار.

للمهمة 3 يجب تشكيل مجموعة فرعية خاصة بك وفقًا للخيار المحدد من CIFAR100 وفقًا للخيار المحدد. 

يتم تنفيذ المختبرات على منصة Google Colab ما عليك سوى الانتقال إلى الرابط في بداية ال Notebook . كما يمكن العمل مع Notebook المختبر محليًا .

### يجب أن يحتوي التقرير على:
- صفحة العنوان
- المهمة مع الخيار المحدد
- لقطات شاشة وتفسيرات قصيرة لكل مرحلة من مراحل العمل المخبري
- جدول نهائي بالنتائج لجميع خيارات التدريب

# الخيارات للمهمة 3

يجب عليك استخدام الفئات التالية من CIFAR100:
<div dir="rtl">
    
1. رقم المجموعة + 15
2. رقم الخيار + 56
  3. ИУ5 (رقم الخيار + 21)؛ ГУИМЦ (80) ؛  (الأجانب(90)  
<div>

# مهام للعمل الذاتي

1. قم بتحليل نتائج تدريب النموذج الخاص بك. ماذا تخبرنا دقة النموذج على مجموعة التدريب واختبار البيانات؟ مع أي الفئات يتعامل النموذج بشكل أفضل ولماذا؟
2. قم بتحليل نتائج التدريب. هل تحدث زيادة في تعلم النموذج الخاص بك؟ ماذا يجب أن تفعل لتقليل ذلك (دون استخدام الانتظام)؟
3. قم بتغيير حجم الدفعة، ولكن حافظ على العدد الإجمالي للتكرارات. قم بتحليل نتائج التدريب مع المعلمات الجديدة. ماذا تغير ولماذا؟
4. قلل من معدل التعلم وزد من العدد الإجمالي للتكرارات لزيادة دقة النموذج.
5. قم بتغيير النموذج الخاص بك - غيّر عدد الخلايا العصبية والطبقات. قم بتحليل نتائج تدريب النموذج الجديد. ابحث عن أفضل المعلمات لهذا النموذج.
6. حدد الإجراءات التي ساعدت في زيادة دقة النموذج الخاص بك وفسر السبب.


# تعليقات على العمل الذاتي
<div dir="rtl">
- يتم تغيير معدل التعلم وحجم الدفعة فقط بعد تحديد لحظة الزيادة في التعلم - الحقبة التي تكون فيها الخطأ على مجموعة الاختبار هو الأدنى. خلاف ذلك، قد يؤدي تحسين الخطوات إلى تعزيز زيادة التعلم (تحسن أثناء التدريب، وتدهور في الاختبار).
</div>
<div dir="rtl">
- يجب أن يؤدي زيادة حجم الدفعة مع نفس عدد التكرارات إلى تحسين التعلم قليلاً (في المتوسط). لأننا نقوم بنفس العدد، ولكن بخطوات أفضل. قد لا يتوافق ذلك مع التجربة لأسباب مختلفة، ولكن من النظرية نتوقع حدوث تحسين ما.
</div>
<div dir="rtl">
- عدد المرات التي تقوم فيها بتغيير معدل التعلم أو حجم الدفعة يجب أن يساوي عدد مرات تغيير عدد العصور للحفاظ على التكرارات. في الممارسة العملية، هذه الشروط ليست ضرورية، لأننا عند إعادة التدريب نغير العديد من المعلمات في نفس الوقت. لكننا نتعلم، لذلك ندرس سلوك كل معلمة على حدة: لا يمكننا مقارنة 5 خطوات كبيرة و7 خطوات صغيرة، لكن يمكننا مقارنة 5 خطوات كبيرة و5 خطوات صغيرة.
</div>
<div dir="rtl">
- عند تغيير النموذج، يجب البحث عن المعلمات الجديدة مرة أخرى - هذا نموذج جديد. ليس من الضروري إعادة شرح جميع الخطوات، فقط قم بذلك بنفسك - ابحث عن زيادة التعلم وابحث عن معدل وحجم دفعة سيكونان أفضل.
</div>

# أسئلة المراقبة للدفاع

1. شبكة عصبية كاملة الاتصال، اشرح الهيكل والحسابات والغرض من الطبقات ومكونات الخلايا العصبية.
2. اذكر عدد الخلايا العصبية والاتصالات والأوزان في شبكة عصبية كاملة الاتصال.
3. وصف مهام الانحدار والتصنيف. ما هي دوال الخسارة المستخدمة في هذه المهام؟
4. وصف هيكل مجموعة البيانات، والغرض من أجزائها.
5. وصف خوارزمية الانحدار العشوائي. اذكر غرض المعلمات. ما الفرق بين الانحدار العشوائي والانحدار على دفعات؟
6. ما هي الحقبة، والتكرار، وحجم الدفعة في التدريب. كيف ترتبط ببعضها؟
7. ما هو التعلم تحت الإشراف، والتعلم بدون إشراف، والتعلم المعزز؟ قدم أمثلة على الأساليب والمهام لكل نوع من أنواع التعلم.
---
# وصف الجدول النهائي

|  تكوين الشبكة العصبية   |  المعلمات الفائقة  |  الدقة  |  التعليق  |
|----------|----------|----------|----------|
|  FC(10), FC(3)   | lr = 0.003, batch_size = 128, epochs = 100  |  اختبار = 70%، تدريب = 98%  |  الخيار الأساسي  |
|  FC(10), FC(3)   | lr = 0.001, batch_size = 128, epochs = 300  |  اختبار = 72%، تدريب = 99%  |  تم تقليل معدل التعلم بمقدار 3 مرات، لتعويض ذلك زاد عدد العصور بنفس المقدار  |


### طرق ودوال PyTorch
<div dir = "rtl">
(Documentation: https://pytorch.org/docs/stable/index.html)
</div>

---

## المكتبات:

<div dir="rtl">* __np__ - مكتبة NumPy للعمل مع المصفوات متعددة الأبعاد للبيانات</div>  
<div dir="rtl">* __pickle__ - مكتبة Pickle لتسلسل وتفكيك هياكل البيانات في لغة Python</div>  
<div dir="rtl">* __sklearn__ - مكتبة تنفذ في الأساس طرق التعلم الآلي الكلاسيكي وأدوات للعمل معها</div>  
<div dir="rtl">* __PIL__ - مكتبة خفيفة الوزن Pillow للعمل مع الصور وعرض العناصر الرسومية مباشرة في Jupyter Notebook</div>  
<div dir="rtl">* __matplotlib__ - مكتبة لرسم الرسوم البيانية، تتكرر في الغالب واجهة برمجة التطبيقات الخاصة بـ Matlab</div>  
<div dir="rtl">* __torch__ - مكتبة PyTorch للتعلم العميق للشبكات العصبية</div>

---


    
<div dir="rtl"><h2>الاختصارات المعتمدة:</h2></div>  
<div dir="rtl">* torch.nn - nn</div>  
<div dir="rtl">* torch.nn.functional - F</div>  
<div dir="rtl">* torch.optim - optim</div>

---



<div dir="rtl"><h1>الطرق</h1></div>  
<div dir="rtl">* __torch.Tensor__ - ينشئ تينسور من مصفوفة Numpy متعددة الأبعاد ويرث نوع بياناته. بشكل افتراضي، يتم تخصيص الذاكرة للتينسورات على وحدة المعالجة المركزية (CPU). عند تعيين علامة __requires_grad__، تتعقب تلقائيًا التدرجات باستخدام محرك autograd، الذي يبني رسمًا بيانيًا ديناميكيًا للحساب. يمكن أيضًا تمكين تتبع التينسور __t__ باستخدام طريقة __t.requires_grad_(True)__ . في هذه الحالة، بعد استدعاء طريقة __backward__، سيتم تسجيل المشتقات في حقل __grad__. يمكن مسح مشتقات التينسور __t__ باستدعاء طريقة __t.grad.zero_()__. لاستخدام طريقة __detach__ لقطع الحسابات غير الضرورية للمشتقات، والتي تنشئ نسخة من التينسور، مع إزالة علامة __requires_grad__، ويتوقف تتبع محرك autograd.</div>


<div dir="rtl">* __torch.numpy__ - ينشئ مصفوفة بيانات NumPy متعددة الأبعاد من التنسور.</div>  
<div dir="rtl">* __torch.item__ - يعيد عددًا، ولكن فقط إذا كانت رتبة التنسور 0. خلاف ذلك، يعطي خطأ ويجب استخدام torch.numpy.</div>  
<div dir="rtl">* __torch.uint8__, __torch.int16__, __torch.int64__, __torch.float32__ - تحويل المصفوفة إلى نوع جديد، مشابه لـ NumPy. يتم استخدام الطريقة .to (على سبيل المثال `t.to(torch.int64)`) للتحويل. بشكل افتراضي، يتم إجراء جميع الحسابات على الرسم البياني في float64، وهناك أيضًا إمكانية استخدام الدقة المختلطة (شيء في float16، وشيء في float64)، ولكن تعتبر هذه تقنية متقدمة.</div>  
<div dir="rtl">* __torch.ones__, __torch.zeros__, __torch.transpose__, __torch.reshape__ - واجهة برمجة التطبيقات مشابهة لـ NumPy.</div>  
<div dir="rtl">* __torch.rand__ - إنشاء تنسور عشوائي بأرقام في النطاق من 0 إلى 1. يتم سرد الأبعاد عبر الفواصل.</div>  
<div dir="rtl">* __torch.t__ - نقل التنسور، مشابه لـ __numpy.transpose__. إذا كان هناك تنسور X، يمكن نقله باستخدام `X.t()`.</div>  
<div dir="rtl">* __torch.sum__ - جمع عناصر التنسور على طول المحور المحدد __axis__. إذا تم الجمع على طول المحور الأخير، يمكن تحديد الرقم -1 بدلاً من ذلك. للحفاظ على أبعاد التنسور الأصلية، يجب تعيين علامة __keepdims__.</div>  
<div dir="rtl">* __torch.maximum__ - يقوم بالمقارنة العنصرية بين التنسورات ويعيد الحد الأقصى من العناصر. في الممارسة العملية، يتم استخدامه لتنفيذ بعض وظائف التنشيط للشبكة العصبية.</div>  
<div dir="rtl">* __torch.mm__ - ضرب التنسورات. بالنسبة لمصفوفتين ثنائيتين الأبعاد بأبعاد (M, N) و (N, K)، سيكون ناتج هذه الطريقة مصفوفة ثنائية الأبعاد بأبعاد (M, K).</div>  
<div dir="rtl">* __torch.exp__ - يعيد نفس وظيفة __numpy.exp__ - رفع التنسور إلى قوة الأساس بصورة عنصرية.</div>  
<div dir="rtl">* __torch.log__ - عملية تسجيل عنصري للتنسور - أخذ اللوغاريتم الطبيعي، وهو العملية العكسية للرفع للقوة.</div>  
<div dir="rtl">* __torch.flatten__ - مشابه لـ NumPy .reshape(-1)، إذا تم تحديد معلمة start_dim، فسيبدأ "تسوية" المصفوفة بدءًا من الرقم المحدد. أي لتحويل التنسور t مع الشكل (100, 32, 32, 3) إلى الشكل (100, 3072) يكفي كتابة <code>torch.flatten(t, start_dim=1).</code></div>  
<div dir="rtl">* __F.one_hot__ - واحدة من الطرق العديدة للحصول على ترميز حار للفئة في شكل تنسور PyTorch. على سبيل المثال، بالنسبة لخمس فئات، سيكون الترميز الحار للفئة "4" هو [0, 0, 0, 1, 0].</div>  
<div dir="rtl">* __torch.utils.data.TensorDataset__ - إنشاء تنسورات مرتبطة، مثل أمثلة التدريب والعلامات المقابلة. يتم تمرير التنسورات كمعلمات. طريقة مقبولة لإنشاء مجموعة بيانات عندما تكون عينة التدريب صغيرة تمامًا وتناسب بالكامل في الذاكرة.</div>  
<div dir="rtl">* __torch.utils.data.DataLoader__ - تعتمد أداة تحميل البيانات في PyTorch على فئة DataLoader. إنها كائن Python يتكرر عبر مجموعة البيانات، مع دعم مجموعة البيانات بأسلوب الخريطة والمكرر؛ إعدادات ترتيب تحميل البيانات؛ تقسيم تلقائي إلى دفعات صغيرة؛ تحميل البيانات في عمليات/خيوط متعددة. أكثر المعلمات فائدة في الباني هي حجم الدفعة الصغيرة __batch_size__ وعدد العمليات المتوازية __num_workers__. لمزج البيانات (لتحقيق تقارب أفضل)، يجب تعيين علامة __shuffle__ إلى True.</div>  
<div dir="rtl">* __torch.save__ - حفظ معلمات النموذج على وسائط التخزين الدائمة. لذلك يتم تمرير model.state_dict() كأول معلمة، حيث model هو النموذج العصبي المدرب، والثاني هو المسار مع اسم الملف.</div>

---

<div dir="rtl"><h1>إنشاء النماذج</h1>:</div>

<div dir="rtl">يتم إنشاء النماذج باستخدام وحدة nn، حيث تم تنفيذ أشهر كتل الشبكات العصبية أو الطبقات في الوحدة، مثل:</div>
<div dir="rtl">* طبقة الاتصال الكامل Linear</div>  
<div dir="rtl">* الطبقة التلافيفية Conv2d</div>  
<div dir="rtl">* تجميع MaxPool2d</div>  
<div dir="rtl">* التطبيع BatchNorm2d</div>  
<div dir="rtl">* مجموعة من وظائف التنشيط ReLU و Softmax و Tanh</div>  
<div dir="rtl">* طبقات تنظيم، مثل Dropout</div>

<div dir="rtl">
    <h4>في هذه التجربة العملية، سوف ندرس فقط كتلتين من كتل الشبكة العصبية من القائمة أعلاه، وهما Linear و ReLU.</h4>
</div>

<div dir="rtl" style="margin-top: 20px;">
    يمكن تعيين النموذج بطريقتين:
</div>

<div dir="rtl" style="margin-top: 20px;">

<div dir="rtl">1. باستخدام nn.Sequential</div>
<div dir="rtl">2. من خلال وراثة الفئة nn.Module</div>

<div>

<div dir="rtl">
    <div dir="rtl">الطريقة الأولى مناسبة لإنشاء نماذج بسيطة بدون تفرعات. يمكن تصورها أساسًا كخط تجميع، حيث يتم تمرير التنسور المدخل عبر سلسلة من التحويلات المتعاقبة للحصول على التنسور الناتج.</div>
    <div dir="rtl">إذا كان من الضروري تطبيق هياكل أكثر تعقيدًا، حيث يمكن أن تنقسم مسارات خط التجميع إلى عدة أجزاء، يتم استخدام nn.Module. يسمح هذا النهج بتنفيذ مجموعة متنوعة من الهياكل.</div>
    <div dir="rtl">لإنشاء بيرسيبترون متعدد الطبقات بسيط مع طبقة مخفية واحدة ودالة غير خطية، يكفي كتابة الكود التالي وفقًا للطريقة الأولى:</div>
</div>

    model = nn.Sequential(
      nn.Linear(input_dims, hidden_dims),
      nn.ReLU(),
      nn.Linear(hidden_dims, num_classes) 
    )

<div dir="rtl">لإنشاء بيرسيبترون متعدد الطبقات بسيط مع طبقة مخفية واحدة ودالة غير خطية، وفقًا للطريقة الثانية، يجب إنشاء فئة (class) ونموذج (model) ككائن من هذه الفئة.</div>

    class MLP(nn.Module):
        def __init__(self, input_dims, hidden_dims, num_classes,
                     *args, **kwargs):
            super(MLP, self).__init__()
            self.fc1 = Linear(input_dims, hidden_dims)
            self.fc2 = Linear(hidden_dims, num_classes)
        
        def forward(self, input):
             x = self.fc1(input)
             x = F.relu(x)
             x = self.fc2(x)
             return x
    
    model = MLP(input_dims, hidden_dims, num_classes) 

<div dir="rtl">في هذه الحالة، يُسمح بتضمين nn.Module و nn.Sequential داخل وحدات (modules) أخرى، مما يسمح بإنشاء بنى نماذج معقدة جدًا.</div>



<div dir="rtl">
    <h4>تدريب النماذج:</h4>
</div>

<div dir="rtl">قبل تدريب النماذج، من الضروري اختيار دالة خسارة (Loss function) ومُحسّن (Optimizer). تتوفر دوال خسارة مختلفة أيضًا في وحدة nn:</div>
<div dir="rtl">* __nn.MSELoss__ - متوسط الخطأ التربيعي (y_true - y_pred)**2</div>
<div dir="rtl">* __nn.BCEWithLogitsLoss__ - الانتروبيا المتقاطعة الثنائية لمهام التصنيف الثنائي</div>
<div dir="rtl">* __nn.CrossEntropyLoss__ - الانتروبيا المتقاطعة الفئوية لمهام التصنيف متعدد الفئات</div>

<div dir="rtl">كبديل، يمكن تنفيذ دالة خسارة (Loss function) يدويًا، على سبيل المثال لـ MSELoss:</div>

    inputs, y = batch
    ...
    output = model(inputs)
    loss = ((output - y)**2).sum()
    ...

<div dir="rtl">
    <h4>المُحسِّنات:</h4>
</div>

<div dir="rtl">تحتوي وحدة __torch.optim__ على المُحسِّنات. هناك العديد من المُحسِّنات للدالة الهدف، ومن الكلاسيكيين هو طريقة النزول العشوائي للتدرج (Stochastic Gradient Descent) أو SGD. في مُنشئ الفئة، يجب تمرير أوزان النموذج، بالإضافة إلى تحديد خطوة التعلم أو learning rate.</div>

<div dir="rtl">لتحويل النموذج إلى حالة التدريب، يجب استدعاء الطريقة __train__. بعد ذلك، يكون النموذج جاهزًا للتدريب.</div>

<div dir="rtl">لتدريب نماذج الشبكات العصبية، يتم استخدام النزول التدرجي وأنواعه، والتي تستند إلى طريقة الاقترابات المتتالية.</div>

<div dir="rtl">خلال عصر واحد، يتم اختيار مرور المُكرر عبر مجموعة البيانات بالكامل، وفي كل تكرار - يتم تحسين معلمات النموذج باستخدام الدفعة الحالية الصغيرة (mini-batch). يقوم PyTorch تلقائيًا بحساب المشتقات عند استدعاء الطريقة __backward__، التي تم تطبيقها على دالة الخسارة.</div>

<div dir="rtl">مع ذلك، عند استدعاء مُجدَّد، ستضاف قيم المشتقات الجديدة إلى المشتقات السابقة المحسوبة. لذلك، لتجنب التأثيرات غير المرغوب فيها، من المعتاد تنظيف القيم السابقة للمشتقات في كل تكرار باستخدام الطريقة __zero_grad__، التي تم تطبيقها على مثيل مُحسِّن الفئة.</div>

<div dir="rtl">لتحديث معلمات الشبكة العصبية، تُستخدم الطريقة __step__، التي تم تطبيقها على مثيل مُحسِّن الفئة.</div>

<div dir="rtl">
    <h4>تحقق من جودة النماذج:</h4>
</div>

<div dir="rtl">لتحويل النموذج إلى حالة التحقق، يجب استدعاء الطريقة __eval__. بعد ذلك، يكون النموذج جاهزًا للتحقق.</div>

<div dir="rtl">يجب قطع التوتر الناتج عن تنبؤات النموذج عن الرسم البياني الحسابي. يتم استخدام الطريقة __detach__، التي تم تطبيقها على التوتر الناتج عن النموذج. خلاف ذلك، قد تحدث تسريبات في الذاكرة. تقوم الطريقة __numpy__ بتحويل التوتر إلى مصفوفة NumPy متعددة الأبعاد.</div>

<div dir="rtl">بشكل افتراضي، يقوم النموذج بإخراج ما يُعرف بـ "لوجيتس" (logits) للفئات، وليس احتمالاتها. للحصول على الاحتمالات، يجب تطبيق دالة التنشيط __Softmax__. ومع ذلك، في الممارسة العملية، ليس من الضروري ذلك، حيث أن قيمة اللوجيتس تتوافق مع احتمالات الفئات، وللحصول على رقم الفئة الأكثر احتمالًا، يمكن تخطي هذه الخطوة. يتم الحصول على رقم الفئة إما من خلال الطريقة __argmax__ أو من خلال الطريقة __argsort__، حيث تسمح الأخيرة بحساب مقاييس مثل Accuracy@5 ومقاييس الترتيب.</div>

<div dir="rtl">
    <h4>استيراد المكتبات الضرورية</h4>
</div>


```python
    import numpy as np
    import torch
    import torch.optim as optim
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import TensorDataset, DataLoader
    import pickle
    from sklearn.metrics import classification_report
    from sklearn.datasets import make_circles, make_moons
    from PIL import Image
    import matplotlib.pyplot as plt
    %matplotlib inline
```

<div dir="rtl">
    <h1>الجزء 1. مشكلة الانحدار وفقًا لنظرية التقريب العالمية، الاشتقاق اليدوي</h1>
</div>

<div dir="rtl"><h2>توليد العينة وتهيئة معلمات الشبكة العصبية</h2> </div>

```python
    X = (np.arange(100)/100 - 0.5).repeat(5)
    
    y = 1/(1+np.exp(-10*X))
    yn = np.random.normal(scale=0.05, size=y.size)+y
    
    plt.plot(X, yn)
    plt.plot(X, y, linestyle='--', c='k')
    ################################################
    tensor_X = torch.Tensor(X.reshape(-1, 1))
    tensor_y = torch.Tensor(yn.reshape(-1, 1))
    
    HIDDEN_SIZE = 64
    # Инициализация весов MLP с одним скрытым слоём
    weights_1 = (torch.rand(1, HIDDEN_SIZE)-.5)/10
    bias_1 = torch.zeros(HIDDEN_SIZE)
    
    weights_2 = (torch.rand(HIDDEN_SIZE, 1)-.5)/10
    bias_2 = torch.zeros(1)
```
import base64

# Your base64 string (truncated for brevity; use the full string you have)
base64_string = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARwAAAB... (your full string)"

# Split the string to remove the data type
header, encoded = base64_string.split(',', 1)

# Decode the image
image_data = base64.b64decode(encoded)

# Write the image data to a file
with open('image.png', 'wb') as image_file:
    image_file.write(image_data)

print("Image saved as 'image.png'")


<div dir="rtl"><h3>تدريب الشبكة العصبية لمشكلة الانحدار</h3></div>

```python
    # Определяем функцию нелинейности
    relu = lambda x: torch.maximum(x, torch.Tensor([0]))
    # Прямой проход
    forward = lambda x: (weights_2.t()*relu((weights_1*x) + bias_1)
                          ).sum(axis=-1,keepdims=True) + bias_2
    loss = lambda y, y_: ((y-y_)**2).sum(axis=-1)
    
    # # обратный проход
    def backward(X, y, y_pred):
        # производная функции потерь по y_pred
        dL = 2*(y_pred-y)
        # значения нейронов скрытого слоя до применения активации
        Ax = (weights_1*X) + bias_1
        # значения нейронов скрытого слоя после применения активации
        A = relu(Ax)
        # производная функции потерь по weight_2
        dW2 = torch.mm(A.t(), dL)
        # производная функции потерь по bias_2
        db2 = dL.sum(axis=0)
        # производная функции потерь по значениям скрытого слоя после активации
        dA = torch.mm(dL, weights_2.t())
        # производная функции потерь по значениям скрытого слоя до активации
        dA[Ax<=0] = 0
        # производная функции потерь по weight_1
        dW = torch.mm(X.t(), dA)
        # производная функции потерь по bias_1
        db = dA.sum(axis=0)
        #print(dW.shape, db.shape, dW2.shape, db2.shape)
        return dW, db, dW2, db2
    
    def optimize(params, grads, lr=0.001):
        # градиентный спуск по всей обучающей выборке
        W1, b1, W2, b2 = params
        W1 -= lr*grads[0]
        W2 -= lr*grads[2]
        b1 -= lr*grads[1]
        b2 -= lr*grads[3]
        return W1, b1, W2, b2
    
    for i in range(50000): # 50 тысяч итераций градиентного спуска == 50 тысяч эпох
      output = forward(tensor_X)
      cur_loss = loss(output, tensor_y)
      grads = backward(tensor_X, tensor_y, output)
      params = [weights_1, bias_1, weights_2, bias_2]
      weights_1, bias_1, weights_2, bias_2 = optimize(params, grads, 1e-4)
      if (i+1)%10000 == 0:
          plt.plot(X, output.numpy(), label=str(i+1), alpha=0.5)
    plt.plot(X, y, linestyle='--', c='k', label='real')
    plt.legend()
    plt.ylim(y.min(), y.max())
    print(cur_loss.numpy().mean())
```

# Часть 2. Бинарная классификация с помощью автодиффиренцирования PyTorch

## Генерация выборки и инициализация параметров нейронной сети

```python
    X = np.random.randint(2, size=(1000, 2))
    
    y = (X[:, 0] + X[:, 1]) % 2 # XOR
    X = X + np.random.normal(0, scale=0.1, size=X.shape)
    #X, y = make_circles(n_samples=1000, noise=0.025)
    #X, y = make_moons(n_samples=1000, noise=0.025)
    plt.scatter(X[:, 0], X[:, 1], c=y)
    ####################################################
    tensor_X = torch.Tensor(X.reshape(-1, 2))
    tensor_y = torch.Tensor(y.reshape(-1, 1))
    
    HIDDEN_SIZE = 16
    # Инициализация весов MLP с одним скрытым слоём
    weights_1 = ((torch.rand(2, HIDDEN_SIZE)-.5)/10).detach().requires_grad_(True)
    bias_1 = torch.zeros(HIDDEN_SIZE, requires_grad=True)
    
    weights_2 = ((torch.rand(HIDDEN_SIZE, 1)-.5)/10).detach().requires_grad_(True)
    bias_2 = torch.zeros(1, requires_grad=True)
```

## Обучение нейронной сети задачи классификации

```python
    # Определяем функцию нелинейности
    def sigmoid(x):
        return 1/(1+torch.exp(-x))
    
    # Прямой проход
    def forward(x):
        hidden = torch.mm(x, weights_1) + bias_1
        hidden_nonlin = sigmoid(hidden)
        output = (weights_2.t()*hidden_nonlin).sum(axis=-1,keepdims=True) + bias_2
        return sigmoid(output)
                           
    # Logloss
    def loss(y_true, y_pred):
        return -1*(y_true*torch.log(y_pred)+(1-y_true)*torch.log(1-y_pred)).sum()
    
    # задаём шаг обучения
    lr = 1e-3
    # задаём число итераций
    iters = 10000
    params = [weights_1, bias_1, weights_2, bias_2]
    losses = []
    for i in range(iters):
        output = forward(tensor_X)
        lossval = loss(tensor_y, output)
        lossval.backward() # тут включается в работу autograd
        for w in params:
            with torch.no_grad():
                w -= w.grad*lr # обновляем веса
            w.grad.zero_() # зануляем градиенты, чтобы не накапливались за итерации
        losses.append(lossval.item())
    # выводим историю функции потерь по итерациям
    plt.plot(losses)
```

## Проверка результатов обучения

```python
    X_diff = X.max() - X.min()
    X_left = X.min() - 0.1*X_diff
    X_right = X.max() + 0.1*X_diff
    grid = np.arange(X_left, X_right, 0.01)
    grid_width = grid.size
    surface = []
    # создаем точки по сетке
    for x1 in grid:
        for x2 in grid:
            surface.append((x1, x2))
    surface = np.array(surface)
    # получаем предсказания для всех точек
    with torch.no_grad():
        Z = forward(torch.Tensor(surface)).detach().numpy()
    # меняем форму в виде двухмерного массива
    Z = Z.reshape(grid_width, grid_width)
    xx = surface[:, 0].reshape(grid_width, grid_width)
    yy = surface[:, 1].reshape(grid_width, grid_width)
    # рисуем разделяющие поверхности классов
    plt.contourf(xx, yy, Z, alpha=0.5)
    # рисуем обучающую выборку
    plt.scatter(X[:, 0], X[:, 1], c=output.detach().numpy()>0.5)
    # задаём границы отображения графика
    plt.xlim(X_left, X_right)
    plt.ylim(X_left, X_right)
```

# Часть 3. Классификация изображений CIFAR100

## Загрузка и распаковка набора данных CIFAR100

```python
    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz
    !tar -xvzf cifar-100-python.tar.gz
```

## Чтение тренировочной и тестовой выборки

```python
    with open('cifar-100-python/train', 'rb') as f:
        data_train = pickle.load(f, encoding='latin1')
    with open('cifar-100-python/test', 'rb') as f:
        data_test = pickle.load(f, encoding='latin1')
    
    # Здесь указать ваши классы по варианту!!!
    CLASSES = [0, 55, 58]
    
    train_X = data_train['data'].reshape(-1, 3, 32, 32)
    train_X = np.transpose(train_X, [0, 2, 3, 1]) # NCHW -> NHWC
    train_y = np.array(data_train['fine_labels'])
    mask = np.isin(train_y, CLASSES)
    train_X = train_X[mask].copy()
    train_y = train_y[mask].copy()
    train_y = np.unique(train_y, return_inverse=1)[1]
    del data_train
    
    test_X = data_test['data'].reshape(-1, 3, 32, 32)
    test_X = np.transpose(test_X, [0, 2, 3, 1])
    test_y = np.array(data_test['fine_labels'])
    mask = np.isin(test_y, CLASSES)
    test_X = test_X[mask].copy()
    test_y = test_y[mask].copy()
    test_y = np.unique(test_y, return_inverse=1)[1]
    del data_test
    Image.fromarray(train_X[50]).resize((256,256))
```

## Создание Pytorch DataLoader'a

```python
    batch_size = 128
    dataloader = {}
    for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],
                            ['train', 'test']):
        tensor_x = torch.Tensor(X)
        tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),
                                         num_classes=len(CLASSES))/1.
        dataset = TensorDataset(tensor_x, tensor_y) # создание объекта датасета
        dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True) # создание экземпляра класса DataLoader
    dataloader
```

## Создание Pytorch модели многослойного перцептрона с одним скрытым слоем

```python
    class Normalize(nn.Module):
        def __init__(self, mean, std):
            super(Normalize, self).__init__()
            self.mean = torch.tensor(mean)
            self.std = torch.tensor(std)
    
        def forward(self, input):
            x = input / 255.0
            x = x - self.mean
            x = x / self.std
            return torch.flatten(x, start_dim=1) # nhwc -> nm
    
    class Cifar100_MLP(nn.Module):
        def __init__(self, hidden_size=32, classes=100):
            super(Cifar100_MLP, self).__init__()
            # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1
            self.norm = Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025])
            self.seq = nn.Sequential(
                nn.Linear(32*32*3, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, classes),
            )
    
        def forward(self, input):
            x = self.norm(input)
            return self.seq(x)
    
    HIDDEN_SIZE = 10
    model = Cifar100_MLP(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))
    model
```

## Выбор функции потерь и оптимизатора градиентного спуска

```python
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.005)
```

## Обучение модели по эпохам

```python
    EPOCHS = 250
    steps_per_epoch = len(dataloader['train'])
    steps_per_epoch_val = len(dataloader['test'])
    for epoch in range(EPOCHS):  # проход по набору данных несколько раз
        running_loss = 0.0
        model.train()
        for i, batch in enumerate(dataloader['train'], 0):
            # получение одного минибатча; batch это двуэлементный список из [inputs, labels]
            inputs, labels = batch
    
            # очищение прошлых градиентов с прошлой итерации
            optimizer.zero_grad()
    
            # прямой + обратный проходы + оптимизация
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            #loss = F.cross_entropy(outputs, labels)
            loss.backward()
            optimizer.step()
    
            # для подсчёта статистик
            running_loss += loss.item()
        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / steps_per_epoch:.3f}')
        running_loss = 0.0
        model.eval()
        with torch.no_grad(): # отключение автоматического дифференцирования
            for i, data in enumerate(dataloader['test'], 0):
                inputs, labels = data
    
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_loss += loss.item()
        print(f'[{epoch + 1}, {i + 1:5d}] val loss: {running_loss / steps_per_epoch_val:.3f}')
    print('Обучение закончено')
```

## Проверка качества модели по классам на обучающей и тестовой выборках

```python
    for part in ['train', 'test']:
        y_pred = []
        y_true = []
        with torch.no_grad(): # отключение автоматического дифференцирования
            for i, data in enumerate(dataloader[part], 0):
                inputs, labels = data
    
                outputs = model(inputs).detach().numpy()
                y_pred.append(outputs)
                y_true.append(labels.numpy())
            y_true = np.concatenate(y_true)
            y_pred = np.concatenate(y_pred)
            print(part)
            print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1),
                                        digits=4, target_names=list(map(str, CLASSES))))
            print('-'*50)
```

## Визуализация весов

```python
    weights = list(model.parameters())[0].detach().numpy()
    print(weights.shape)
    fig, ax = plt.subplots(1, weights.shape[0], figsize=(3*weights.shape[0], 3))
    for i, ω in enumerate(weights):
        ω = ω.reshape(32, 32, 3)
        ω -= np.percentile(ω, 1, axis=[0, 1])
        ω /= np.percentile(ω, 99, axis=[0, 1])
        ω = np.clip(ω, 0, 1) 
        ax[i].imshow(ω)
```

# Описание методов библиотек

### Методы и функции NumPy:

(Подробнее в документации https://numpy.org/doc/1.22/reference/index.html)

* __np.array__ - создание массива из списка или другого массива
* __np.shape__ - выводит размерность многомерного массива (т.е. для массива 2х2 будет выведен кортеж (2, 2))
* __np.size__ - выводит число элементов в массиве (т.е. для массива 2х2 будет выведено число 4)
* __np.uint8__, __np.int16__, __np.int64__, __np.float32__ - приведение массива к новому типу, при этом в памяти выделяется место под новый массив выбранного типа. Число после типа обозначет, сколько бит данных используется для хранения одного элемента массива. Для хранения картинок зачастую используется экономный uint8 - беззнаковый 8-битный целочисленный тип данных (диапазон чисел 0-255)
* __np.ones__, __np.zeros__  - создание уже заполненных массивов либо единицами, либо нулями. В качестве аргумента передается список или кортеж с требуемой размерностью. Например `np.ones((10,))` создаст вектор из 10 единичек. А `np.zeros((32, 32, 3))` создаст двузмерный массив разрешением 32 на 32 пикселя с 3 каналами. На практике используется для проверки архитектуры модели в прямом направлении
* __np.arange__ - создание уже заполненного массива в виде возрастающей арифметической прогресии от первого аргумента до второго аргумента не включительно с шагом, который задаётеся третьим аргументом. Первый и третий аргументы можно опускать, в таком случае получается компактная запись `np.arange(3)` => [0, 1, 2]
* __np.repeat__ - дублирование элементов массива на количество, указанное первым аргументом. Таким образом, для массива `arr = [0, 1]` `arr.repeat(2)` вернёт [0, 0, 1, 1]
* __np.exp__ - применение поэлементной операции потенциирования к массиву
* __np.random.normal__ - генерация массива, заполненного случайными нормальными величинами со стандартным отклонением, задающимся через аргумент scale и со средним значением, равным аргументу mean. Число элементов в массиве задаётся числом или списком, переданным аргументу size.
* __np.random.randint__ - генерация массива, заполненного случайными целыми числами в диапазоне, задающимся аналогично __np.arange__. Число элементов в массиве задаётся числом или списком, переданным аргументу size.
* __np.reshape__  - буквально изменение размерности многомерного массива с учётом числа элементов. В качестве аргумента передается многомерный массив, а также список или кортеж с новой размерностью. Например `np.reshape([0, 1, 2, 3], (2,2))` создаст двухмерный массив размером 2х2. При этом в памяти новый массив не выделяется, а меняется лишь способ обхода по нему. Разрешается также и следующий способ вызова метода: `arr.reshape(2, 2)`. Обратите внимание на отсутствие дополнительных скобок. Если вместо конкретного числа подставить -1, то размерность будет подсчитана автоматически. На практике используется для выпрямление картинок в виде одномерного массива: `X.reshape(-1, 3072)`# [100, 32, 32, 3] -> [100, 3072]
* __np.transpose__  - переименование осей многомерного массива. Для работы с изображениями принято два формата NHWC и NCHW (N - число картинок в массиве, C - число каналов, H - высота, W - ширина). В качестве аргумента передается многомерный массив, а также список или кортеж с новой расстановкой осей. Например `np.transpose([[0, 1, 2, 3]], (1,0))` создаст двухмерный вектор-столбец [[[0], [1], [2], [3]]. Заметьте, что отсчет осей начинается с 0. На практике используется для перевода NHWC в NCHW и обратно. В первом случае 0 ось N остаётся на своём первом месте, первая и вторая оси H и W сдвигаются на одну позицию вправо, а 3 ось - C ставится на второе место. Т.е. получим следующую перестановку: [0, 3, 1, 2] 
* __np.isin__ - аналог SQL оператора IN, поэлементная проверка вхождения массива в коллекцию. `np.isin([0, 2, 1], [2, 3])` вернёт [False, True, False]
* __индексирование__ - выбор подмассива или среза массива осуществляется с помощью квадратных скобок []. Если `arr = np.array([2, 1, 0])`, то `arr[0]` вернёт первый элемент. `arr[[0, 1]]` - обращение по индексу, `arr[[True, False, True]]` - обращение по булевой маске. Заметьте, что обращение по индексу необязательно должно совпадать с размерностью массива, в отличие от обращения по маске. На практике удобно записывать значения маски в отдельную переменную. Для выбора конкретного столбца в многомерном массиве используется синтаксис срезов [:, k], где k - номер столбца. Если k равняется -1, то используется последний столбец или элемент. Так, например, для массива `arr = np.array([[0, 1], [2, 3], [4, 5])` выражение `arr[:, 0]` вернет массив [0, 2, 4]. Поскольку используется индекс срезов (стандартный синтаксис Python), то можно также выполнять срезы многомерных массивов. Для предыдущего примера `arr[1:2, 0:1]` вернёт [[2]]
* __np.unique__ - аналог SELECT DISTINCT в SQL. При стандартных параметрах возвращает одномерный подмассив, содержащий уникальные элементы. Если указать выставить флаг __return_inverse__, то вернется массив с номерами отсчётов массива с уникальными элементами. По сути выполняется Label Encoding
* __np.concatenate__ - конкатенация многомерного массива вдоль указанной оси. Номер оси указывается через аргумент __axis__. Например может быть использован для объединения нескольких признаков или нескольких наборов данных. В контексте изображений может использоваться для объединения или склейки нескольких изображений в одно как вертикально, так и горизонтально. В контексте звука - склеивание двух аудиодорожек.
* __np.max__, __np.min__ - возвращает максимальный и минимальный элементы массива вдоль указанной оси, соответственно. Если номер оси не указан, то возвращается число. Номер оси указывается через аргумент __axis__. Если указывается -1, то полагается, что используется последний номер оси. Разрешается также и вызов функции в качестве метода многомерного массива: `arr.max()`
* __np.argmax__ - возвращает индекс максимального элемента массива вдоль указанной оси. Если номер оси не указан, то возвращается первый индекс, соответвующих максимальному значению в массиве, т.е. одно число. Номер оси указывается через аргумент __axis__. Если указывается -1, то полагается, что используется последний номер оси. На практике используется для расчёта метрики доли правильных ответов модели (Accuracy). Разрешается также и вызов функции в качестве метода многомерного массива: `arr.argmax(axis=-1)`

### Методы и функции Pickle
(Документация: https://docs.python.org/3/library/pickle.html)

* __pickle.dump__ - сериализация структуры данных Python. Первым аргументом идёт сама структура, а вторым FileObject. При этом FileObject должен быть открыт в режиме записи байт (wb). Можно указать кодировку байт (big endian/ little endian). Тем самым можно хранить на постоянном носителе стандартные структуры данных, в том числе NumPy массивы.
* __pickle.load__ - десериализация структуры данных Python. Первым аргументом идёт FileObject. При этом FileObject должен быть открыт в режиме чтения байт (rb). Можно указать кодировку байт (big endian/ little endian). Тем самым можно загружать ранее сохранённые структуры данных, что может быть полезно, если для их создания требуется длительное время (например, параметры модели глубокого обучения)


### Методы и функции Sklearn
(Документация: https://scikit-learn.org/stable/modules/classes.html)

* __datasets.make_circles__, __datasets.make_moons__ - генерация синтетической обучающей выборки для задачи классификации, возвращает X - двухмерный массив с числом примеров и числом признаков (признаков 2), а также одномерный массив с метками классов (0 или 1)

* __metrics.classification_report__ - cоздает текстовый отчет, показывающий основные метрики классификации (доля правильных ответов, полнота, точность, f1-мера). В качестве первого аргумента передаются истинные метки класса, в качестве второго - метки класса, предсказанные моделью. Дополнительные полезные аргументы: digits - число выводимых знаков после запятой (по умолчанию 2), output_dict - возвращает словарь с расчитанными метриками вместо строки, sample_weight - расчитывает взвешенные метрики на основе веса каждого примера

* __metrics.confusion_matrix__ - вычисляет матрицу ошибок модели для оценки точности классификации. Матрица ошибок идеальной модели имеет значения только на главной диагонали. Может быть использована для подсчёта всех классических метрик классификации (доля правильных ответов, полнота, точность, специфичность, f1-мера).

### Методы и функции PIL

(Документация: https://pillow.readthedocs.io/en/stable/)

* __Image.fromarray__ - cоздает объект Image на основе двухмерного массива или двухмерного массива с каналами. Часто ругается, если тип данных не uint8. Часто ругается, если производится попытка создать черно-белое изображения из картинки размерностью (W, H, 1). Для того, чтобы получить обратно массив из объекта Image, достаточно привести его к NumPy массиву, например np.array(img)

* __Image.resize__ - меняет разрешение изображения с помощью интерполяции. Первым аргументом указывается список с новой шириной и высотой изображения. При желании можно указать тип интерполяции через аргумент resample. Поддерживаемые значения: PIL.Image.NEAREST, PIL.Image.BOX, PIL.Image.BILINEAR, PIL.Image.HAMMING, PIL.Image.BICUBIC, PIL.Image.LANCZOS. По умолчанию используется бикубическая интерполяция.

* __Image.convert__ - переводит изображение из одной цветовой схемы в другую. Новая цветовая схема передается строкой, L - черно белая, LA - черно-белая с прозрачностью, RGB - стандартная цветовая схема с 3 каналами, RGBA - стандартная цветовая схема с 3 каналами цвета и одним каналом прозрачности, HSV - альтернативное цветовое представление и т.д.

* __Image.open__ - считывает изображение по указанному пути в виде строки или FileObject. При создании набора данных может неправильно определить формат (например L вместо RGB), поэтому рекомендуется сразу после open приводить к нужному формату при помощи метода convert

* __Image.save__ - сохраняет изображение по указанному пути в виде строки или FileObject. Если указывается FileObject, то нужно также указать формат изображения в аргументе format, например 'PNG' или 'JPEG'

### Методы и функции Matplotlib

(Документация: https://matplotlib.org/stable/api/index.html)

Принятые сокращения:
* matplotlib.pyplot - plt

Методы:
* __plt.plot__ - рисует график по точкам и соединяет их линией. Первым аргументом передаются x-координаты, вторым - у-координаты. Если не передавать второй аргумент, х координаты будут приняты за у, а в качестве х будут использованы отсчёты массива. Дополнительные полезные аргументы: linestyle - тип отображаемой линиии ('--', '-', '-.' и т.д.), color - цвет линии ('k' - черный, 'r' - красный, 'white' - белый и т.д.), alpha - прозрачность линии, число от 0 (линия не видна) до 1 (нет прозрачности), label - текстовая метка данного графика.
* __plt.scatter__ - рисует график по точкам юез соединения линиями. Первым аргументом передаются x-координаты, вторым - у-координаты. Если не передавать второй аргумент, х координаты будут приняты за у, а в качестве х будут использованы отсчёты массива. Дополнительные полезные аргументы: s - размер точек, color - цвет точек ('k' - черный, 'r' - красный, 'white' - белый и т.д.), alpha - прозрачность точек, число от 0 (линия не видна) до 1 (нет прозрачности), label - текстовая метка данного графика.
* __plt.contourf__ - рисует заполненные контурные линии, разграничивающие границы.
* __plt.show__ - принудительная отрисовка графика, может использоваться для вывода нескольких графиков в одном блоке кода.
* __plt.legend__ - отображает ранее указанные метки графиков
* __plt.xlim__ - ограничивает диапазон x-координат от первого до второго аргумента. По умолчанию диапазон горизонтальной оси подбирается автоматически на основе используемых данных. Для задания диапозана значений горизонтальной оси вручную и используется данный метод
* __plt.ylim__ - аналогично __plt.xlim__, но для вертикальнйо оси.



